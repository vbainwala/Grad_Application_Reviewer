{
    "ID": "171318992",
    "SOP": "Haonan Wang\u2019s Sop I am highly interested in pursuing a Ph.D. in database systems. To prepare for the interdisciplinary challenges in the Ph.D. study, I worked on several systems research projects, including using machine learning (ML) to solve system problems. Although my previous research experience mainly focused on using ML for systems, I became more driven in using non-ML ways to optimize systems after working in the industry and developing automated ways to optimize the performance of real-world databases. Reinforcement Learning for CDN caches My undergraduate research focused on using ML to optimize system performance. Throughout my seven-month internship at MIT, I was fortunate to conduct research with Prof. Mohammad Alizadeh and his Ph.D. student Hongzi Mao on using reinforcement learning (RL) to improve the caching algorithm performance for content distribution networks (CDNs). During the first phase of the project, I created a platform that allowed me to easily benchmark and test new RL algorithms for reducing CDN caching algorithm byte miss ratio. This platform became part of the Park Project, an open research platform that allows applying RL to various computer system problems. My work has been presented as part of a NeurIPS 2019 paper. In the second phase, I worked on applying deep RL to automatically discover high-performance CDN caching policies under different network characteristics. Despite successful applications of RL in robotics and other computer systems, prior attempts of RL on web caching still were not competitive, even compared with simple heuristics. I found that the root problem for previous failures leads to the long reward delays in large caching systems. To solve this problem, I developed a subsampling algorithm: The strategy is to reduce the cache size and subsample the trace using hashing with the same reduction ratio. Moreover, I helped develop a general theory for a class of RL problems that share the invariance property and allow problem reduction for efficient learning. We published our work in the ML for Systems workshop at NeurIPS 2020. Additionally, I also came up with a priority-based model that can derive all the traditional cache algorithms, while allowing an RL agent to learn which mixture of the models to engage for specific caching traffic. Building Infrastructure to Accelerate ML on Mobile During my undergraduate internship at MEGVII, a startup that designs image recognition and deep learning software, I succeeded in accelerating the inference stage of computer vision tasks on mobile with ARM GPU. The idea is to use OpenCL to parallelly execute basic operations like pooling and rotation in the computer vision tasks with multiple cores on a mobile GPU. However, the biggest challenge was exploiting the ARM GPU's computing power to get the best possible performance. I designed a translation framework during the development to allow seamless data alignment (logic data index and the GPU data structure index). I also used the Image Objects in the OpenCL framework. This data structure allows extra speedup compared with normal GPU parallel operation execution. My framework is currently deployed on all ARM-GPU mobile phones that use our company's platform, which reduces the latency by 10x compared to the prior state-of-the-art GPU parallel algorithm for millions of daily users. Using Machine Learning to Generate Synthetic Workload During my time as a Master\u2019s Student at CMU, I was advised by Prof. Andy Pavlo to work on filling the gap between the research and reality for ML-based configuration tuning. Despite the great success ML-based configuration tuning has achieved in research, we found it hard to implement the workload replay session mentioned in all the previous papers when trying to implement the algorithm in practice. It is difficult to acquire customers' workloads (e.g., SQL traces) because trace collectors for MySQL/PostgreSQL have implementation issues and can cause high runtime overhead when collecting the full SQL trace. However, all the previous papers assume they can have the workload trace for the workload replay session to train the ML model. Haonan Wang\u2019s Sop To solve this problem, I proposed generating synthetic workloads based on DBMS internal runtime metrics and using the synthetic workload to train the ML model. The generator must build everything (including data, schemas, and queries) from scratch. To simplify the process of creating the synthetic workload, I used an existing database benchmark framework, the YCSB workload generator, as the building block for our workload generator. To control the behavior of the YCSB workload generator, I designed a framework that uses the Bayesian Optimization algorithm to derive the proper parameters so that it can generate a synthetic workload that is similar to the original customer database. This year, I presented my current research result at CMU, MIT, Harvard, and Columbia Database groups. Building SaaS to Improve Customers' Database Performance After graduating from CMU, I joined Prof. Pavlo at his OtterTune startup as a software engineer and worked on building a production SaaS to apply ML-based configuration tuning research to the real world. At OtterTune, when trying to develop our ML-based tuning for more customers, we find that many of our users need more database knowledge, which creates problems for using ML-based tuning in practice. For example, when missing indexes or inefficient queries caused by our customers can limit the possible improvement of the tuning algorithm. Besides, our customers sometimes set inappropriate knob values that restrict the tuning space for ML tuning. Inspired by this, we started developing features to help them correctly use their databases. During my work at OtterTune, my main job was to develop heuristic rules-based checkers that check the condition of customers' databases and give them optimization suggestions based on the check results. I mainly focused on two features: Database Health Check and Query Health Check. The basic idea for Database Health Check is to inspect the customer databases' health condition using internal runtime metrics based on some heuristic rules. The biggest challenge is to provide accurate solutions instead of simply interpreting what is wrong. I designed estimation models based on PostgreSQL and MySQL operational logic to calculate suggested values for configuration knobs when detecting abnormal database runtime behaviors. The core function of our Query Health Check is to find anti-patterns in our customers' queries, which are some common mistakes our customers make when they write SQL code. According to my data analysis, many of our customers' queries have anti-patterns that can cause unused I/O usage and wrong index selection during execution. I have developed a new query checker package that uses static analysis to examine our customers' queries and provide suggestions for improvement. The package will parse SQL into an abstract syntax tree (AST) based on the database type, and then perform pattern matching on the tree to extract relevant information. Another part of my job at Ottertune is to analyze our customers' workload data to gain insights for our feature development. This also allows me to interact with real-world database data from a researcher's perspective. I noticed that some problems are overlooked in the research community but can cause significant issues in practice. For example, many of our customers use OLTP databases (like PostgreSQL) to execute both short-term transactions and long-term analytical tasks, which can lead to suboptimal performance on OLTP databases. Currently, the research community still uses OLTPBench to evaluate the performance of different tuning algorithms. However, we may need a new benchmark framework to measure the effectiveness of these algorithms on hybrid workloads, which are common in practice. Another problem is that many customers use object-relational mapping (ORM) libraries to generate and maintain SQLs. However, ORMs can often generate inefficient queries. In practice, it can be difficult to detect these bad queries on the database side because the database does not have much information about application logic. We can overcome this issue by starting optimization from the upper level and performing static analysis on the application code, using the results to optimize generated queries. Summary Haonan Wang\u2019s Sop Throughout my research experience, I have had opportunities to use ML to solve different problems in the system. These research experiences enabled me to be a capable researcher with proficiency in ML and systems. Throughout my industry experience, I gained exposure to building complex systems and a better understanding of how people use their databases in practice. Apart from learning from these experiences and acquiring more knowledge, my time in academia and industry has shaped my research taste. I realized there is more to pursuing extreme performance improvements in ideal test environments; it is also critical to gain interpretable and robust results. I believe that Columbia University offers the best resources for me to contribute to database research. I am drawn to the vibrant and hard-working community at Columbia, and I am excited to see the cutting-edge research being conducted by the university's world-renowned professors. I am very impressed by the work of Professor Eugene Wu on optimizing interactive data applications, such as simplifying the process of generating interactive data analysis interfaces. During my time in the industry, I have realized that there is still a significant gap between users and data. There is much work to be done to improve how users interact with and make use of data. I am also very interested in Kenneth A. Ross's research on improving query performance in various scenarios. With my passion for and curiosity about machine learning and computer systems, combined with my diverse background in these fields, I am confident that I can make valuable contributions to the database systems area through research at Columbia.",
    "Publications": [
        "Learning Caching Policies with Subsampling",
        "Park: An Open Platform for Learning-Augmented Computer Systems"
    ],
    "Education": {
        "Graduate": {
            "Institution": "Carnegie Mellon University",
            "Degree": "Master of Science",
            "Major": "Computational Data Science",
            "GPA": "3.82"
        },
        "Undergraduate": {
            "Institution": "Peking University",
            "Degree": "Bachelor of Science",
            "Major": "Data Science",
            "GPA": "3.58"
        }
    },
    "Faculty Members": ["Eugene Wu","Luis Gravano","Kenneth Ross"],
    "Recommendation Letters": {
        "1": "Dear Colleague, Allow me to introduce myself with my academic background first, as I might not show up as a regular recommendation letter writer. My name is Hongzi Mao and I did my PhD from MIT with research focus on applying Reinforcement Learning to large computer systems. My publications are listed in https://scholar.google.com/citations?user=zQbwxcwAAAAJ . After graduation, I went to the startup world and now I\u2019m co-founder and CTO of Hologram Labs, which is a tech company building virtual avatar infrastructure. I am delighted to write this letter to strongly recommend Haonan Wang for your graduate program. During his eight months of study and research at MIT, Haonan has exhibited many excellent qualities that speak to his potential as a graduate student. He worked closely with myself (I was then a PhD student) on applying reinforcement learning (RL) to optimize caching policies. In this project, Haonan identified and tackled important challenges that have previously prohibited RL from being used successfully in caching problems. In the following, I will describe Haonan's good traits and qualities from our day to day collaborations. First of all, Haonan has a keen sense for identifying interesting technical challenges. When Haonan reached out to my advisor Prof. Mohammad Alizadeh, he was curious about exploring new ways of applying RL techniques to computer systems. We then gave him a recent HotNets workshop paper that suggested large potential for improving learning-based caching policies. In particular, it highlighted that RL methods have failed to reach state-of-the-art performance in caching problems for content distribution networks (CDN). We thought it would be interesting to understand why this is, but we didn\u2019t have a concrete sense of the research challenges or what approaches would be worth investigating. Exceeding our expectations, Haonan discovered, on his own, that the key challenge is that the large size of CDN caches (e.g., hundreds of GBs hosting millions of objects) significantly delays observing the impact of a caching decision on the hitrate (or reward of an RL agent). Haonan realized that this delay is orders of magnitude longer than modern RL applications (e.g., AlphaGo deals with hundreds of actions per game; OpenAI Dota game only lasts for tens of thousands of steps) and thus require fundamentally new RL algorithms. To solve the delayed reward problem, Haonan observed that we need to reduce the problem scale to a manageable size. His approach was to subsample the problem space, learn a policy on the smaller sample using RL, and generalize the learned model to the original large problem. This approach is interesting because the reward delay can be made significantly smaller on the sampled problem, enabling RL algorithms to learn much more effectively. A principled way to sample in caching is to sample the request access pattern by some factor k and correspondingly shrink the cache size by the same factor. It can be shown that this sampling strategy preserves the key statistics of the cache, like the hitrate. Moreover, Haonan realized this idea of subsampling can also apply to a more general class of RL problems, and working with two graduate students, he helped formalize the concept of sampling in Markov Decision Processes to derive conditions under which learning strong policies for sampled problem spaces yields strong policies in the original problem. Having identified the research direction, Haonan independently and efficiently gathered all the background knowledge, much like a mature PhD student. On the machine learning side, he studied the state-of-the-art of deep reinforcement learning on his own using several online sources. He managed to take advantage of both prior implementations from our group and other open codebases from DeepMind and OpenAI. Importantly, he didn\u2019t just simply take prior work as black box --- Haonan understood many hidden tricks and the principles behind them (e.g., how to adaptively control the exploration process in policy gradient algorithms) to get things working. On the systems front, Haonan wrote a caching simulator from scratch andmade it compatible with prior work released by Daniel Berger (a postdoc at CMU) for comparison. Haonan is the first author of a Machine Learning for Systems workshop paper at NeurIPS this year about his RL-based caching work. Haonan\u2019s cache implementation also later became one of the first systems merged into Park, which is an open platform for RL research in computer systems. A paper about Park was published in NeurIPS 2019, with Haonan as a co- author. Throughout the caching project, Haonan was always willing to take responsibility and execute every aspect of the project. He did all the heavy lifting of writing code and doing the experiments. He also gave a nice talk about his project in our group. This was all done while he undertook a heavy course load. During the spring term, Haonan took four courses, two of which were at the graduate level. Despite his heavy workload, Haonan managed his time well. He met regularly with me and also sent my advisor Mohammad regular and detailed updates on his progress. He also received full grades for all his classes. After all, Haonan is simply just a really fun person to work with. I am influenced many times by his passion and more importantly his funness in doing research. Even when we hit some downtime where nothing seems to work, Haonan was able to find different ways of questioning the fundamentals and make actionable progress. For example, the initial subsampling implementation for caching did not just work. Instead of aimlessly and painfully debugging the whole RL training pipeline end-to-end, Haonan redirected our attention to whether the caching statistics remains invariant after subsampling. The moment he conducted a simple experiment for checking the cache hit rate after subsampling, it became immediately obvious that we must subsample the trace by random hash on object IDs (independent of the object distribution). Haonan has a talent for translating his resilience of solving a complex problem to an enjoyable activity that makes everyone around him appreciate the interesting aspects. Having observed how Haonan discovered interesting research problems, found unique ways of approaching the challenges and his diligence in carrying out his project from beginning to end, I believe Haonan will do well in a top PhD program. I recommend him for admission without reservation. Sincerely, Hongzi Mao",
        "2": "AndyPavlo AssociateProfessorwithIndefiniteTenure,ComputerScienceDepartment December29,2022 TL;DR:IlikeHaonan. HeknowsalotmoreaboutMLthanIdo. Ihavelasttwoyearsconvertinghimfrom a ML researcher to a database researcher. He is now ready for a competitive Ph.D. program. You should admithim. Towhomitmayconcern: IampleasedtorecommendHaonanWang(Haonan)foradmissiontoyourPh.D.program. Ihaveknown Haonansince2021whenhejoinedmydatabasestartup(OtterTune1)asasummerintern. Iwasthenhis master\u2019sadviseratCarnegieMellonUniversityforonesemester. ThenIcontinuedcollaboratingwithhim forthepastyearonaresearchsideprojectwhilehewasafull-timeemployeeatOtterTune. Hisresearch with me is on machine learning (ML) to improve database management systems (DBMSs) behavior. He has the rare quality of understanding both the internals of complex systems and ML algorithms beyond cursory knowledge. If I were taking a new student next year, I would admit him to our Ph.D. program. ButsinceIamnotacceptingnewstudents,Ihavetoldhimthatheshouldconsidertheothertopdatabase groups. Butmylossisourgain;youshouldadmithim. I first met Haonan via a recommendation from two of my OtterTune employees. They mentioned that a strong CMU MS student was interested in joining OtterTune as a summer intern. Haonan was in the sameMSprogramtheyrecentlygraduatedfromandwenttothesameundergraduateuniversity(PKU)in China. ButinsteadofmajoringintheeliteComputerScienceprogramlikemyemployees,Haonancame fromanevenmoreselectiveprogramatPKUthatfocusedonmachinelearning(ML)anddatascience. My understandingisthatthisisPKU\u2019sversionofTsinghua\u2019sprestigiousYaoClassprogram. Given Haonan\u2019s strong ML background, he was a perfect fit for OtterTune. We are building a SaaS that automatically improves the performance and efficiency of database management systems (DBMS) like PostgreSQL and MySQL. The high-level idea of OtterTune is that it collects runtime telemetry from the database (e.g., disk I/O, CPU utilization) and then trains machine learning (ML) models that recommend configuration parameters to improve the DBMS\u2019s performance. One recurring issue with our ML-based approach is that database workloads are unpredictable; thus, there could be spikes in usage that cause performancedegradation. Forexample,acompanymaydeployanewfeatureinitsupstreamapplication thatdramaticallyincreasesthenumberofqueriesitissuestotheDBMS,increasingquerylatencydueto contention. ButOtterTune\u2019soriginalalgorithmscouldnotdeterminewhethersuchdegradationisdueto apoorrecommendationmadebyourserviceorachangeintheapplication\u2019sbehavior. WhenHaonanjoinedOtterTuneasaninterninsummer2021,wehadhimdevelopautomatedmethodsof identifying such performance anomalies in our customers\u2019 databases. Using Facebook\u2019s Kats library, he createdamodeltodetectchangepointsinworkloadtime-seriesdata. Tolocatethechangeboundaries,he iterativelytesteddifferentchoicesbycalculatingthestatisticalsignificanceofthechangepoints. Hethen comparedthemagnitudestoreducetheinfluenceofseasonalitywithashortperiodofhistoricaldataasa 1https://ottertune.com Gates-HillmanCenter9019,5000ForbesAve,PittsburghPA15217 Phone:443-242-4047 \u2022 Email:pavlo@cs.cmu.edu \u2022 Web:https://cs.cmu.edu/\u223cpavloAndyPavlo AssociateProfessorwithIndefiniteTenure,ComputerScienceDepartment reference. Thisworkisoutsidemyresearcharea,butIwasimpressedwiththeresultshesharedwithour teamattheendofthesummer. During his internship, I had several conversations with Haonan about what he wanted to do next in his career. Hehopedtogetinvolvedinmoresystems-focusedresearchandapplyforPh.D.programs. Hewas previouslyworkingwithanotherprofessoratCMU,buthisresearchprojectwithhimwasadeadend. My understanding is that the professor runs a large group, and Haonan was assigned to work with a Ph.D. studentthatshowedlittleinterestinmentoringHaonan. SinceIwasimpressedwith ShortName\u2019sabilities at OtterTune, I agreed to advise him for his MS capstone project. I was on LOA from the university that year to focus on OtterTune and my biological daughter, so I was not taking on any new students. But I madeanexceptionforHaonan. Haonan\u2019s researchproject with mein the fallof 2021 was tryingto solve theproblem of tuninga DBMS withouthavingaccesstotheactualdatabasecontentsoritsworkloadonanon-productioninstance.Thisis asignificantassumptionthatalmostallML-for-databasesresearchmakes.Butintherealworld,customers are not willing or even able to grant unfettered access to their database not capture its workload (i.e., a trace of every SQL statement that the DBMS executes for some time). They are also not willing or able to clone the database to a separate instance. Thus, for most customers, the only database available to tuneistheirproductionsystems,severelylimitinghowaggressivelyanML-basedsolutioncanexplorethe solutionspacetofindanoptimalconfiguration. Haonan devised an automated method to generate a synthetic workload that mimics the behavior of an actualworkloadwithouthavingaccesstothedatabaseorworkload. Theideaistotrainamodelthatmaps DBMS telemetry (e.g., # of tuples read/written, resource consumption) to a distribution of transactions fromexistingbenchmarks(e.g.,TPC-C,YCSB).Forexample,ifarealdatabaseisread-only,thenthemodel will generate a YCSB mixture that only executes read-only queries. He then feeds this mixture into our benchmark framework (BenchBase) and executes the workload on a database approximately the same size as the original (target) database. Then the last step is to use OtterTune\u2019s optimization algorithm to recommendaconfigurationthatimprovesthesyntheticworkload\u2019sperformanceandthenshowthatthe sameconfigurationalsohelpstheoriginaldatabaseinthesameway. AttheendofhislastsemesteratCMUinDecember2021,Haonanhadpromisingpreliminaryresultsthat showedthathisapproachworkedforsimplisticusecases(e.g.,hecouldsynthesizeaworkloadthatclosely mimicked another existing benchmark). Since he still wanted to apply for Ph.D. programs, Haonan told mehewantedtodelaygraduationfromCMUandspendanextrasemesterworkingonresearchwithme. IinsteadconvincedhimtocomeworkatOtterTunefull-timeasanon-researchengineer,andthenIwould continueworkingwithhimonnights/weekendsonhisprojecttoturnitintoeitherafullSIGMOD/VLDB paperoratleastaworkshoppaper. StartinginJanuary2022, HaonanjoinedOtterTune, andheandImetweeklytoworkonhisproject. We expanded his models to consider other configuration parameters for the benchmark framework, like the transaction submission rate and database size. Over the past year, we tried running his approach using Gates-HillmanCenter9019,5000ForbesAve,PittsburghPA15217 Phone:443-242-4047 \u2022 Email:pavlo@cs.cmu.edu \u2022 Web:https://cs.cmu.edu/\u223cpavloAndyPavlo AssociateProfessorwithIndefiniteTenure,ComputerScienceDepartment real-world databases to measure its efficacy. Unfortunately, after many iterations, Haonan\u2019s workload synthesizer did not make a notable difference against OtterTune\u2019s original workload mapping algorithm from our SIGMOD 2017 paper. The customer workloads we had access to were just too simple, and our previous simple approach was too effective. This negative result should not be a reflection of Haonan\u2019s abilities;researchdoesnotalwaysworkoutasonehoped. Haonanwascircumspectandmatureaboutthe outcome. Weplanonpursuingananalysisprojectin2023aboutthetrendsweseeindatabaseworkloadsoverperiods oftime. Haonanisgoingtoworkwithme(andothersatOtterTune)toturnourresultsintoapaperbefore hereturnstograduateschool. Haonan\u2019swritingandpresentationskillsneedwork. Ispentalotoftimeworkingwithhimonhisrecent talkatseveraldatabasegroupsthispastsemester. Afterseveralpracticetalksandroundsoffeedback,he didnotputtogetherapresentationthatwasuptomy(high?) standards. ThisissomethingthatHaonan\u2019s new adviser will have to work on with him. The good news is that Haonan\u2019s English speaking skills are betterthanmostotherinternationalstudentsIhavetaught. Hedidacompetentjobatpresentinghisideas andstatusreportsatourcompanymeetings. Hewillhavenoproblemcommunicatingwithothersduring hisPh.D.career. I put Haonan in the same category as my previous MS students, Dongsheng Yang (now a Ph.D. student atPrinceton)andLilyLiu(currentlyaPh.D.studentatBerkeley). Theyarebothintelligent,hardworking, anddedicated. TheyalsocanquicklyabsorbnewmaterialaboutDBMSinternals. Lilywasabettersystems programmerthanbothofthem. HaonanhasbetterEnglishskillsthanDongsheng. Haonan will do well as a Ph.D. student. I enjoyed the time I spent with him at both CMU and Otter- Tune. IlikeHaonanalotandwilladvocateforourdepartmenttoadmithimtoourPh.D.program. Iam encouragingHaonantotalkwithotherCMUprofessorsandvisitotherschools. AndyPavlo Gates-HillmanCenter9019,5000ForbesAve,PittsburghPA15217 Phone:443-242-4047 \u2022 Email:pavlo@cs.cmu.edu \u2022 Web:https://cs.cmu.edu/\u223cpavlo"
    },
    "Research Areas": [
        "Databases and Data Management"
    ]
}