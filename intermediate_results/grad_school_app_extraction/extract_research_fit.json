[{"ID": "171318992", "Application": {"SOP": "Haonan Wang\u2019s Sop I am highly interested in pursuing a Ph.D. in database systems. To prepare for the interdisciplinary challenges in the Ph.D. study, I worked on several systems research projects, including using machine learning (ML) to solve system problems. Although my previous research experience mainly focused on using ML for systems, I became more driven in using non-ML ways to optimize systems after working in the industry and developing automated ways to optimize the performance of real-world databases. Reinforcement Learning for CDN caches My undergraduate research focused on using ML to optimize system performance. Throughout my seven-month internship at MIT, I was fortunate to conduct research with Prof. Mohammad Alizadeh and his Ph.D. student Hongzi Mao on using reinforcement learning (RL) to improve the caching algorithm performance for content distribution networks (CDNs). During the first phase of the project, I created a platform that allowed me to easily benchmark and test new RL algorithms for reducing CDN caching algorithm byte miss ratio. This platform became part of the Park Project, an open research platform that allows applying RL to various computer system problems. My work has been presented as part of a NeurIPS 2019 paper. In the second phase, I worked on applying deep RL to automatically discover high-performance CDN caching policies under different network characteristics. Despite successful applications of RL in robotics and other computer systems, prior attempts of RL on web caching still were not competitive, even compared with simple heuristics. I found that the root problem for previous failures leads to the long reward delays in large caching systems. To solve this problem, I developed a subsampling algorithm: The strategy is to reduce the cache size and subsample the trace using hashing with the same reduction ratio. Moreover, I helped develop a general theory for a class of RL problems that share the invariance property and allow problem reduction for efficient learning. We published our work in the ML for Systems workshop at NeurIPS 2020. Additionally, I also came up with a priority-based model that can derive all the traditional cache algorithms, while allowing an RL agent to learn which mixture of the models to engage for specific caching traffic. Building Infrastructure to Accelerate ML on Mobile During my undergraduate internship at MEGVII, a startup that designs image recognition and deep learning software, I succeeded in accelerating the inference stage of computer vision tasks on mobile with ARM GPU. The idea is to use OpenCL to parallelly execute basic operations like pooling and rotation in the computer vision tasks with multiple cores on a mobile GPU. However, the biggest challenge was exploiting the ARM GPU's computing power to get the best possible performance. I designed a translation framework during the development to allow seamless data alignment (logic data index and the GPU data structure index). I also used the Image Objects in the OpenCL framework. This data structure allows extra speedup compared with normal GPU parallel operation execution. My framework is currently deployed on all ARM-GPU mobile phones that use our company's platform, which reduces the latency by 10x compared to the prior state-of-the-art GPU parallel algorithm for millions of daily users. Using Machine Learning to Generate Synthetic Workload During my time as a Master\u2019s Student at CMU, I was advised by Prof. Andy Pavlo to work on filling the gap between the research and reality for ML-based configuration tuning. Despite the great success ML-based configuration tuning has achieved in research, we found it hard to implement the workload replay session mentioned in all the previous papers when trying to implement the algorithm in practice. It is difficult to acquire customers' workloads (e.g., SQL traces) because trace collectors for MySQL/PostgreSQL have implementation issues and can cause high runtime overhead when collecting the full SQL trace. However, all the previous papers assume they can have the workload trace for the workload replay session to train the ML model. Haonan Wang\u2019s Sop To solve this problem, I proposed generating synthetic workloads based on DBMS internal runtime metrics and using the synthetic workload to train the ML model. The generator must build everything (including data, schemas, and queries) from scratch. To simplify the process of creating the synthetic workload, I used an existing database benchmark framework, the YCSB workload generator, as the building block for our workload generator. To control the behavior of the YCSB workload generator, I designed a framework that uses the Bayesian Optimization algorithm to derive the proper parameters so that it can generate a synthetic workload that is similar to the original customer database. This year, I presented my current research result at CMU, MIT, Harvard, and Columbia Database groups. Building SaaS to Improve Customers' Database Performance After graduating from CMU, I joined Prof. Pavlo at his OtterTune startup as a software engineer and worked on building a production SaaS to apply ML-based configuration tuning research to the real world. At OtterTune, when trying to develop our ML-based tuning for more customers, we find that many of our users need more database knowledge, which creates problems for using ML-based tuning in practice. For example, when missing indexes or inefficient queries caused by our customers can limit the possible improvement of the tuning algorithm. Besides, our customers sometimes set inappropriate knob values that restrict the tuning space for ML tuning. Inspired by this, we started developing features to help them correctly use their databases. During my work at OtterTune, my main job was to develop heuristic rules-based checkers that check the condition of customers' databases and give them optimization suggestions based on the check results. I mainly focused on two features: Database Health Check and Query Health Check. The basic idea for Database Health Check is to inspect the customer databases' health condition using internal runtime metrics based on some heuristic rules. The biggest challenge is to provide accurate solutions instead of simply interpreting what is wrong. I designed estimation models based on PostgreSQL and MySQL operational logic to calculate suggested values for configuration knobs when detecting abnormal database runtime behaviors. The core function of our Query Health Check is to find anti-patterns in our customers' queries, which are some common mistakes our customers make when they write SQL code. According to my data analysis, many of our customers' queries have anti-patterns that can cause unused I/O usage and wrong index selection during execution. I have developed a new query checker package that uses static analysis to examine our customers' queries and provide suggestions for improvement. The package will parse SQL into an abstract syntax tree (AST) based on the database type, and then perform pattern matching on the tree to extract relevant information. Another part of my job at Ottertune is to analyze our customers' workload data to gain insights for our feature development. This also allows me to interact with real-world database data from a researcher's perspective. I noticed that some problems are overlooked in the research community but can cause significant issues in practice. For example, many of our customers use OLTP databases (like PostgreSQL) to execute both short-term transactions and long-term analytical tasks, which can lead to suboptimal performance on OLTP databases. Currently, the research community still uses OLTPBench to evaluate the performance of different tuning algorithms. However, we may need a new benchmark framework to measure the effectiveness of these algorithms on hybrid workloads, which are common in practice. Another problem is that many customers use object-relational mapping (ORM) libraries to generate and maintain SQLs. However, ORMs can often generate inefficient queries. In practice, it can be difficult to detect these bad queries on the database side because the database does not have much information about application logic. We can overcome this issue by starting optimization from the upper level and performing static analysis on the application code, using the results to optimize generated queries. Summary Haonan Wang\u2019s Sop Throughout my research experience, I have had opportunities to use ML to solve different problems in the system. These research experiences enabled me to be a capable researcher with proficiency in ML and systems. Throughout my industry experience, I gained exposure to building complex systems and a better understanding of how people use their databases in practice. Apart from learning from these experiences and acquiring more knowledge, my time in academia and industry has shaped my research taste. I realized there is more to pursuing extreme performance improvements in ideal test environments; it is also critical to gain interpretable and robust results. I believe that Columbia University offers the best resources for me to contribute to database research. I am drawn to the vibrant and hard-working community at Columbia, and I am excited to see the cutting-edge research being conducted by the university's world-renowned professors. I am very impressed by the work of Professor Eugene Wu on optimizing interactive data applications, such as simplifying the process of generating interactive data analysis interfaces. During my time in the industry, I have realized that there is still a significant gap between users and data. There is much work to be done to improve how users interact with and make use of data. I am also very interested in Kenneth A. Ross's research on improving query performance in various scenarios. With my passion for and curiosity about machine learning and computer systems, combined with my diverse background in these fields, I am confident that I can make valuable contributions to the database systems area through research at Columbia.", "Recommendation_Letters": {"1": "Dear Colleague, Allow me to introduce myself with my academic background first, as I might not show up as a regular recommendation letter writer. My name is Hongzi Mao and I did my PhD from MIT with research focus on applying Reinforcement Learning to large computer systems. My publications are listed in https://scholar.google.com/citations?user=zQbwxcwAAAAJ . After graduation, I went to the startup world and now I\u2019m co-founder and CTO of Hologram Labs, which is a tech company building virtual avatar infrastructure. I am delighted to write this letter to strongly recommend Haonan Wang for your graduate program. During his eight months of study and research at MIT, Haonan has exhibited many excellent qualities that speak to his potential as a graduate student. He worked closely with myself (I was then a PhD student) on applying reinforcement learning (RL) to optimize caching policies. In this project, Haonan identified and tackled important challenges that have previously prohibited RL from being used successfully in caching problems. In the following, I will describe Haonan's good traits and qualities from our day to day collaborations. First of all, Haonan has a keen sense for identifying interesting technical challenges. When Haonan reached out to my advisor Prof. Mohammad Alizadeh, he was curious about exploring new ways of applying RL techniques to computer systems. We then gave him a recent HotNets workshop paper that suggested large potential for improving learning-based caching policies. In particular, it highlighted that RL methods have failed to reach state-of-the-art performance in caching problems for content distribution networks (CDN). We thought it would be interesting to understand why this is, but we didn\u2019t have a concrete sense of the research challenges or what approaches would be worth investigating. Exceeding our expectations, Haonan discovered, on his own, that the key challenge is that the large size of CDN caches (e.g., hundreds of GBs hosting millions of objects) significantly delays observing the impact of a caching decision on the hitrate (or reward of an RL agent). Haonan realized that this delay is orders of magnitude longer than modern RL applications (e.g., AlphaGo deals with hundreds of actions per game; OpenAI Dota game only lasts for tens of thousands of steps) and thus require fundamentally new RL algorithms. To solve the delayed reward problem, Haonan observed that we need to reduce the problem scale to a manageable size. His approach was to subsample the problem space, learn a policy on the smaller sample using RL, and generalize the learned model to the original large problem. This approach is interesting because the reward delay can be made significantly smaller on the sampled problem, enabling RL algorithms to learn much more effectively. A principled way to sample in caching is to sample the request access pattern by some factor k and correspondingly shrink the cache size by the same factor. It can be shown that this sampling strategy preserves the key statistics of the cache, like the hitrate. Moreover, Haonan realized this idea of subsampling can also apply to a more general class of RL problems, and working with two graduate students, he helped formalize the concept of sampling in Markov Decision Processes to derive conditions under which learning strong policies for sampled problem spaces yields strong policies in the original problem. Having identified the research direction, Haonan independently and efficiently gathered all the background knowledge, much like a mature PhD student. On the machine learning side, he studied the state-of-the-art of deep reinforcement learning on his own using several online sources. He managed to take advantage of both prior implementations from our group and other open codebases from DeepMind and OpenAI. Importantly, he didn\u2019t just simply take prior work as black box --- Haonan understood many hidden tricks and the principles behind them (e.g., how to adaptively control the exploration process in policy gradient algorithms) to get things working. On the systems front, Haonan wrote a caching simulator from scratch andmade it compatible with prior work released by Daniel Berger (a postdoc at CMU) for comparison. Haonan is the first author of a Machine Learning for Systems workshop paper at NeurIPS this year about his RL-based caching work. Haonan\u2019s cache implementation also later became one of the first systems merged into Park, which is an open platform for RL research in computer systems. A paper about Park was published in NeurIPS 2019, with Haonan as a co- author. Throughout the caching project, Haonan was always willing to take responsibility and execute every aspect of the project. He did all the heavy lifting of writing code and doing the experiments. He also gave a nice talk about his project in our group. This was all done while he undertook a heavy course load. During the spring term, Haonan took four courses, two of which were at the graduate level. Despite his heavy workload, Haonan managed his time well. He met regularly with me and also sent my advisor Mohammad regular and detailed updates on his progress. He also received full grades for all his classes. After all, Haonan is simply just a really fun person to work with. I am influenced many times by his passion and more importantly his funness in doing research. Even when we hit some downtime where nothing seems to work, Haonan was able to find different ways of questioning the fundamentals and make actionable progress. For example, the initial subsampling implementation for caching did not just work. Instead of aimlessly and painfully debugging the whole RL training pipeline end-to-end, Haonan redirected our attention to whether the caching statistics remains invariant after subsampling. The moment he conducted a simple experiment for checking the cache hit rate after subsampling, it became immediately obvious that we must subsample the trace by random hash on object IDs (independent of the object distribution). Haonan has a talent for translating his resilience of solving a complex problem to an enjoyable activity that makes everyone around him appreciate the interesting aspects. Having observed how Haonan discovered interesting research problems, found unique ways of approaching the challenges and his diligence in carrying out his project from beginning to end, I believe Haonan will do well in a top PhD program. I recommend him for admission without reservation. Sincerely, Hongzi Mao", "2": "AndyPavlo AssociateProfessorwithIndefiniteTenure,ComputerScienceDepartment December29,2022 TL;DR:IlikeHaonan. HeknowsalotmoreaboutMLthanIdo. Ihavelasttwoyearsconvertinghimfrom a ML researcher to a database researcher. He is now ready for a competitive Ph.D. program. You should admithim. Towhomitmayconcern: IampleasedtorecommendHaonanWang(Haonan)foradmissiontoyourPh.D.program. Ihaveknown Haonansince2021whenhejoinedmydatabasestartup(OtterTune1)asasummerintern. Iwasthenhis master\u2019sadviseratCarnegieMellonUniversityforonesemester. ThenIcontinuedcollaboratingwithhim forthepastyearonaresearchsideprojectwhilehewasafull-timeemployeeatOtterTune. Hisresearch with me is on machine learning (ML) to improve database management systems (DBMSs) behavior. He has the rare quality of understanding both the internals of complex systems and ML algorithms beyond cursory knowledge. If I were taking a new student next year, I would admit him to our Ph.D. program. ButsinceIamnotacceptingnewstudents,Ihavetoldhimthatheshouldconsidertheothertopdatabase groups. Butmylossisourgain;youshouldadmithim. I first met Haonan via a recommendation from two of my OtterTune employees. They mentioned that a strong CMU MS student was interested in joining OtterTune as a summer intern. Haonan was in the sameMSprogramtheyrecentlygraduatedfromandwenttothesameundergraduateuniversity(PKU)in China. ButinsteadofmajoringintheeliteComputerScienceprogramlikemyemployees,Haonancame fromanevenmoreselectiveprogramatPKUthatfocusedonmachinelearning(ML)anddatascience. My understandingisthatthisisPKU\u2019sversionofTsinghua\u2019sprestigiousYaoClassprogram. Given Haonan\u2019s strong ML background, he was a perfect fit for OtterTune. We are building a SaaS that automatically improves the performance and efficiency of database management systems (DBMS) like PostgreSQL and MySQL. The high-level idea of OtterTune is that it collects runtime telemetry from the database (e.g., disk I/O, CPU utilization) and then trains machine learning (ML) models that recommend configuration parameters to improve the DBMS\u2019s performance. One recurring issue with our ML-based approach is that database workloads are unpredictable; thus, there could be spikes in usage that cause performancedegradation. Forexample,acompanymaydeployanewfeatureinitsupstreamapplication thatdramaticallyincreasesthenumberofqueriesitissuestotheDBMS,increasingquerylatencydueto contention. ButOtterTune\u2019soriginalalgorithmscouldnotdeterminewhethersuchdegradationisdueto apoorrecommendationmadebyourserviceorachangeintheapplication\u2019sbehavior. WhenHaonanjoinedOtterTuneasaninterninsummer2021,wehadhimdevelopautomatedmethodsof identifying such performance anomalies in our customers\u2019 databases. Using Facebook\u2019s Kats library, he createdamodeltodetectchangepointsinworkloadtime-seriesdata. Tolocatethechangeboundaries,he iterativelytesteddifferentchoicesbycalculatingthestatisticalsignificanceofthechangepoints. Hethen comparedthemagnitudestoreducetheinfluenceofseasonalitywithashortperiodofhistoricaldataasa 1https://ottertune.com Gates-HillmanCenter9019,5000ForbesAve,PittsburghPA15217 Phone:443-242-4047 \u2022 Email:pavlo@cs.cmu.edu \u2022 Web:https://cs.cmu.edu/\u223cpavloAndyPavlo AssociateProfessorwithIndefiniteTenure,ComputerScienceDepartment reference. Thisworkisoutsidemyresearcharea,butIwasimpressedwiththeresultshesharedwithour teamattheendofthesummer. During his internship, I had several conversations with Haonan about what he wanted to do next in his career. Hehopedtogetinvolvedinmoresystems-focusedresearchandapplyforPh.D.programs. Hewas previouslyworkingwithanotherprofessoratCMU,buthisresearchprojectwithhimwasadeadend. My understanding is that the professor runs a large group, and Haonan was assigned to work with a Ph.D. studentthatshowedlittleinterestinmentoringHaonan. SinceIwasimpressedwith ShortName\u2019sabilities at OtterTune, I agreed to advise him for his MS capstone project. I was on LOA from the university that year to focus on OtterTune and my biological daughter, so I was not taking on any new students. But I madeanexceptionforHaonan. Haonan\u2019s researchproject with mein the fallof 2021 was tryingto solve theproblem of tuninga DBMS withouthavingaccesstotheactualdatabasecontentsoritsworkloadonanon-productioninstance.Thisis asignificantassumptionthatalmostallML-for-databasesresearchmakes.Butintherealworld,customers are not willing or even able to grant unfettered access to their database not capture its workload (i.e., a trace of every SQL statement that the DBMS executes for some time). They are also not willing or able to clone the database to a separate instance. Thus, for most customers, the only database available to tuneistheirproductionsystems,severelylimitinghowaggressivelyanML-basedsolutioncanexplorethe solutionspacetofindanoptimalconfiguration. Haonan devised an automated method to generate a synthetic workload that mimics the behavior of an actualworkloadwithouthavingaccesstothedatabaseorworkload. Theideaistotrainamodelthatmaps DBMS telemetry (e.g., # of tuples read/written, resource consumption) to a distribution of transactions fromexistingbenchmarks(e.g.,TPC-C,YCSB).Forexample,ifarealdatabaseisread-only,thenthemodel will generate a YCSB mixture that only executes read-only queries. He then feeds this mixture into our benchmark framework (BenchBase) and executes the workload on a database approximately the same size as the original (target) database. Then the last step is to use OtterTune\u2019s optimization algorithm to recommendaconfigurationthatimprovesthesyntheticworkload\u2019sperformanceandthenshowthatthe sameconfigurationalsohelpstheoriginaldatabaseinthesameway. AttheendofhislastsemesteratCMUinDecember2021,Haonanhadpromisingpreliminaryresultsthat showedthathisapproachworkedforsimplisticusecases(e.g.,hecouldsynthesizeaworkloadthatclosely mimicked another existing benchmark). Since he still wanted to apply for Ph.D. programs, Haonan told mehewantedtodelaygraduationfromCMUandspendanextrasemesterworkingonresearchwithme. IinsteadconvincedhimtocomeworkatOtterTunefull-timeasanon-researchengineer,andthenIwould continueworkingwithhimonnights/weekendsonhisprojecttoturnitintoeitherafullSIGMOD/VLDB paperoratleastaworkshoppaper. StartinginJanuary2022, HaonanjoinedOtterTune, andheandImetweeklytoworkonhisproject. We expanded his models to consider other configuration parameters for the benchmark framework, like the transaction submission rate and database size. Over the past year, we tried running his approach using Gates-HillmanCenter9019,5000ForbesAve,PittsburghPA15217 Phone:443-242-4047 \u2022 Email:pavlo@cs.cmu.edu \u2022 Web:https://cs.cmu.edu/\u223cpavloAndyPavlo AssociateProfessorwithIndefiniteTenure,ComputerScienceDepartment real-world databases to measure its efficacy. Unfortunately, after many iterations, Haonan\u2019s workload synthesizer did not make a notable difference against OtterTune\u2019s original workload mapping algorithm from our SIGMOD 2017 paper. The customer workloads we had access to were just too simple, and our previous simple approach was too effective. This negative result should not be a reflection of Haonan\u2019s abilities;researchdoesnotalwaysworkoutasonehoped. Haonanwascircumspectandmatureaboutthe outcome. Weplanonpursuingananalysisprojectin2023aboutthetrendsweseeindatabaseworkloadsoverperiods oftime. Haonanisgoingtoworkwithme(andothersatOtterTune)toturnourresultsintoapaperbefore hereturnstograduateschool. Haonan\u2019swritingandpresentationskillsneedwork. Ispentalotoftimeworkingwithhimonhisrecent talkatseveraldatabasegroupsthispastsemester. Afterseveralpracticetalksandroundsoffeedback,he didnotputtogetherapresentationthatwasuptomy(high?) standards. ThisissomethingthatHaonan\u2019s new adviser will have to work on with him. The good news is that Haonan\u2019s English speaking skills are betterthanmostotherinternationalstudentsIhavetaught. Hedidacompetentjobatpresentinghisideas andstatusreportsatourcompanymeetings. Hewillhavenoproblemcommunicatingwithothersduring hisPh.D.career. I put Haonan in the same category as my previous MS students, Dongsheng Yang (now a Ph.D. student atPrinceton)andLilyLiu(currentlyaPh.D.studentatBerkeley). Theyarebothintelligent,hardworking, anddedicated. TheyalsocanquicklyabsorbnewmaterialaboutDBMSinternals. Lilywasabettersystems programmerthanbothofthem. HaonanhasbetterEnglishskillsthanDongsheng. Haonan will do well as a Ph.D. student. I enjoyed the time I spent with him at both CMU and Otter- Tune. IlikeHaonanalotandwilladvocateforourdepartmenttoadmithimtoourPh.D.program. Iam encouragingHaonantotalkwithotherCMUprofessorsandvisitotherschools. AndyPavlo Gates-HillmanCenter9019,5000ForbesAve,PittsburghPA15217 Phone:443-242-4047 \u2022 Email:pavlo@cs.cmu.edu \u2022 Web:https://cs.cmu.edu/\u223cpavlo"}, "Education": {"Graduate": {"Institution": "Carnegie Mellon University", "Degree": "Master of Science", "Major": "Computational Data Science", "GPA": "3.82"}, "Undergraduate": {"Institution": "Peking University", "Degree": "Bachelor of Science", "Major": "Data Science", "GPA": "3.58"}}, "Publications": ["Learning Caching Policies with Subsampling", "Park: An Open Platform for Learning-Augmented Computer Systems"], "Faculty_Members": ["Eugene Wu", "Luis Gravano", "Kenneth Ross"], "Research_Areas": ["Databases and Data Management"]}, "research_experience": [{"research_area": "Databases and Data Management", "projects": "Reinforcement Learning for CDN caches", "skills": ["Machine Learning", "Reinforcement Learning", "Systems Design", "Benchmarking", "Data Analysis"], "description": "Conducted research on improving caching algorithms for content distribution networks using reinforcement learning (RL). Developed a platform for testing RL algorithms, created a subsampling algorithm to reduce cache size, and formalized a theory for RL problems. Published research at NeurIPS 2020 and contributed to the Park Project.", "collaboration": "Worked closely with Prof. Mohammad Alizadeh and Ph.D. student Hongzi Mao, receiving regular feedback and guidance, and collaborating on research initiatives.", "recommendation": "Hongzi Mao noted Haonan's ability to identify important research challenges and tackle them effectively, exceeding expectations and demonstrating independence and efficiency in gathering knowledge."}, {"research_area": "Databases and Data Management", "projects": "Using Machine Learning to Generate Synthetic Workload", "skills": ["Machine Learning", "Synthetic Data Generation", "Bayesian Optimization", "Statistical Modeling"], "description": "Developed a method to create synthetic workloads based on DBMS metrics to train ML models in the absence of actual workload traces. Leveraged the YCSB workload generator and Bayesian Optimization to optimize parameters, and presented results at multiple prestigious institutions like MIT and Harvard.", "collaboration": "Collaborated with Prof. Andy Pavlo, receiving mentorship and guidance throughout the project, leading to continued discussions and feedback.", "recommendation": "Andy Pavlo highlighted Haonan's ability to understand complex systems and ML, and noted his growth from an ML researcher to a database-focused researcher, indicating his readiness for competitive Ph.D. programs."}, {"research_area": "Databases and Data Management", "projects": "Building SaaS to Improve Customer's Database Performance", "skills": ["Software Engineering", "Heuristic Rule Development", "Static Analysis", "Data Analytics"], "description": "Contributed to developing a SaaS product that provides ML-based configuration tuning for databases. Focused on building features to improve database health and performance through heuristic checks and static analysis of SQL queries, addressing real-world database issues.", "collaboration": "Worked alongside a team of engineers and researchers at OtterTune, effectively communicating with team members to develop features that meet customer needs.", "recommendation": "Pavlo remarked on Haonan's work ethic and his prior internship's successful contributions to performance anomaly detection, which aligns with real-world applications of DBMS research."}]}, {"ID": "703313960", "Application": {"SOP": "I am motivated to pursue a Ph.D. in the Computer Science Program at Columbia to fulfill my research interests. Through experiences working as a research assistant with Professor Xi He, Florian Kerschbaum, and Ian Munro, I developed my research interests in both Database Management Systems (DBMS) and Data Privacy fields. Specifically, I am interested in developing applications to help data analysts better understand, and draw inferences about sensitive data, while protecting users\u2019 personal information. Inspired by the topics covered in an algorithm class, I reached out to Professor Ian Munro to work on the majority problem. This problem involves determining the majority color from a set of balls with two colors. The project aimed to arrive at tighter upper and lower bounds for the number of comparisons required to solve this problem under a three-way comparison model. I made a valuable contribution by formalizing an algorithm that reduced the information-theoretic upper bound by a logarithmic magnitude asymptotically. This project ignited my passion in academic research. After my first project, the bulk of my work focused on developing applications that support private data exploration. In my next project, I built an interactive system that allows data curators to specify personalized privacy guarantees and data analysts to answer queries under such privacy guarantees. I worked with Professor Xi He, for this research project, which was published at the VLDB 2021 demo track. The differential privacy definition can be extended to protect combinations of sensitive attributes. In fact, data curators might want to extend such a definition by declaring customized indistinguishability conditions. Blowfish Privacy provides a solution through a graph, using nodes and edges to represent sensitive tuples. Yet, this brought up another problem \u2013 it\u2019s infeasible for data curators to define the graph, especially for huge datasets. For the sake of usability, I extended Blowfish Privacy such that data curators may define attribute-wise (column- wise) privacy policies. More specifically, two tuples are indistinguishable if they have similar values of some attribute. After discussing my solution with Professor He and other group members, I led the drafting of the paper, coded up a prototype that dynamically generates privacy policies according to incoming queries, and presented our work at the conference. This project shed light on the importance of extending abstract definitions to concrete use cases, and equipped me with skills in designing and building an interactive system. Following this line of research, I joined another project with Professor Florian Kerschbaum in the data privacy area. In this project, we looked at membership inference attacks where a machine learning model leaks sensitive information about its training dataset. However, the performance of those attacks under differentially private learning were far lower than the theoretical bound. As we designed and conducted several successful attacks, a paper by Google Research presented the same problem along with several attacks that overlapped with ours. However, a contemporary paper did not mean that all the work we have done was in vain; as differential private learning aims to protect users\u2019 data against unrealistic adversaries, we started to question the necessity of applying it in the real world. Specifically, privacy concerns might not rise before the model began to overfit, or \u2018memorize\u2019 the training set. Based on this observation, we developed a framework that evaluated the tradeoff between privacy level and utility of a model after each training epoch. Hence, it became possible to determine privacy-utility tradeoffs for different sets of training parameters through a pareto front. We applied non-differential privacy defenses to models including pretraining, early stopping, and gradient clipping, and evaluated these models against those generated through differential private training. Eventually, we observed that differential private learning often resulted in suboptimal performance. This project demonstrated to me that it is crucial to consider both theory and practice in research projects. Currently, I am working with Professor Xi He again. We are developing a system that reuses cached responses to answer incoming queries differentially privately under a given accuracy requirement. I joined the project halfway, so the key structure of the system had already been determined. However, there was a potential flaw where a particular matrix might not have a full column rank to satisfy the prerequisites to apply an existing algorithm correctly. To deal with the problem, I implemented an algorithm to transform the existing matrices into a compatible full- rank form, and formalized a proof of correctness. Moreover, I implemented one of the three main modules that cleverly picked accurate cached responses to answer a new query. Additionally, I developed a prototype of a related work for evaluation against our system. Aside from my technical contributions, I also designed interactive use-cases for our system and extensively tested our implementation against these cases. This project is still ongoing, and I will be involved in extending our system to handle queries with multiple attributes. We plan to submit our work to VLDB 2022. From the four projects mentioned above, I cultivated intensive research working habits, and identified my future research interest in doctoral study. I would like to further explore data privacy and DBMS because databases are the foundation for many topics in computer science. After careful research into both schools and professors, I believe the spirit of Columbia database research group aligns the best with my research interests. In particular, I am fascinated by Professor Eugene Wu\u2019s project on Smoke query engine in which the relationship between input and output data of a workflow is monitored to make potential inferences using declarative logic. As a result, great performance improvements are promising on interactive data visualization. In return with the great resources in the Columbia database research group, I believe my research background and experiences in building interactive data exploration systems makes me a valuable addition to the research team at Columbia.", "Recommendation_Letters": {"1": "Nov 30, 2021 Xi He Assistant Professor Department of Computer Science University of Waterloo Web: https://cs.uwaterloo.ca/~xihe/ Email: xi.he@uwaterloo.ca To Whom It May Concern: I have had the pleasure of working with Jerry (Jiaxiang) Liu in the past two years. Jerry is a highly talented and self-driven undergraduate student in Computer Science at the University of Waterloo. He took my course CS348 on database management in Winter 2020 and received an excellent grade (top 1%) for this course. I learned that he had a great interest in research and admitted him as an undergraduate research assistant (URA) in 2020-2021. I worked with Jerry on multiple research projects related to privacy-preserving database systems. One of the works has turned into a demo paper published at the International Conference on Very Large Data Bases (VLDB), a top-tier database venue. Jerry is a self-motivated and fast learner. The first project that Jerry worked with me is on designing and developing an interactive database system for sensitive data exploration, named BlowfishDB. This project requires a good understanding of the state-of-the-art privacy notions and their corresponding algorithms. Within a month, Jerry has managed the basic concepts and algorithms. He applied a privacy notion, Blowfish privacy, on real databases, that allows a flexible trade-off space between privacy levels on the sensitive databases and the query utility. Jerry also implemented the key algorithms for such a trade- off and integrated these algorithms into a query-answering interface, together with another student. In addition, to assist the data owners to specify their desired privacy policies, Jerry created an interface for them to visualize the privacy policies and explore the trade-off. The first end-to-end prototype for this work was completed by Jerry, as a part-time URA. I was very impressed by his productivity and enthusiasm with work assigned to him. Jerry was also greatly involved in the writing of the paper for this project and the demonstration of the system at the conference (VLDB\u201921). This paper proposed a new privacy notion, Dynamic Blowfish, to improve the performance of the database system.Jerry contributed significantly to the formalization of this new privacy notion and the proofs for the utility and performance guarantees. Jerry needed some guides at the beginning of the analysis, but he asked very good questions when learning the proofs and was able to generalize the proofs for different use cases. Jerry also worked with one of my graduate students to prepare the demonstration video of this work at the conference. The video was well done in illustrating the motivation, the use cases, and the results of this work. Jerry played a very important role in the completion of this demo work. Jerry is currently an active research member for another of my research project. He worked with a few graduate students to develop a cache structure for answering differentially private queries. In this project, he was able to figure out quickly the bottleneck of the previous prototypes and developed useful test cases to evaluate the usability of this cache structure. Jerry can work very well with his team members. He can communicate well and play a leading role in the development of the project when coming to his assigned part. This work is in preparation for submission. I think all this research experience has well prepared Jerry for graduate school. Overall, Jerry is definitely a top undergraduate student I have met at the University of Waterloo, with strong technical skills and great research potential. Hence, I strongly recommend Jerry for your graduate program. Sincerely, Xi He", "2": "1 December 2021 To whom it may concern: I am writing this letter in very strong support of Jiaxiang (Jerry) Liu\u2019s application for your graduate program. I am an Associate Professor in the University of Waterloo\u2019s School of Computer Science, NSERC/RBC chair in Data Security, and an ACM Distinguished Scientist. I know Jerry as my undergrad research assistant (URA, full-time) in the Winter 2021 term. URAs work on aspects of a research problem, in my group usually as a part of a larger team. I am very selective in choosing URAs and only accept students whose grades are in the top 5% of undergrad students. Jerry was working on our project on evaluating differential private stochastic gradient descent as a defense for membership inference attacks on deep neural networks co-supervised by postdoc Simon Oya. We are currently preparing a submission to the PETS conference, with Jerry as the first author. This project was very intensive on implementation and experimentation and the crucial aspect was to use a proper method such that the experimental results are sound, replicable and generalize to other settings. Jerry was responsible for the implementation using different machine learning techniques (regularization, etc.) and then executing and documenting the experiments such that we could draw reliable conclusions. This work requires very high attention to detail since even small mistakes can distort the results significantly. With the help of Simon, Jerry produced very good results that we are summarizing in the publication. Jerry is very inquisitive and always suggested new research directions, such as using SAM regularization which is one of the main conclusions of the work. During the entire process which required several iterations and included several setbacks (including initial work for which we were beaten to publication), Jerry remained motivated and dedicated to the result. I would assess that Jerry is among the top 1% of Waterloo\u2019s computer science undergrad students motivated for grad school. He also has the necessary skills and talent to succeed which he has shown during our collaboration. Jerry is a very nice person to work with. He is always in a good mood and keen to explain his results. He has indicated to me that he wants his graduate studies to focus on machine learning. Jerry certainly has knowledge and skills in this topic that exceed the education in the classroom. My research rather focuses on securing machine learning as in Jerry\u2019s URA project, but I would have gladly accepted to supervise him. I have no doubt that Jerry will do well in your graduate program. I highly recommend him without any reservation. Should you have any questions, please do not hesitate to contact me. Sincerely, Florian Kerschbaum Associate Professor of Computer Science, NSERC/RBC Chair in Data Security"}, "Education": {"Graduate": {}, "Undergraduate": {"Institution": "University Of Waterloo", "Degree": "Bachelor of Mathematics", "Major": "Computer Science/Statistics/Combinatorics & Optimization", "GPA": "3.8"}}, "Publications": ["Catch a Blowfish Alive: A Demonstration of Policy-Aware Differential Privacy for Interactive Data Exploration", "Generalization Techniques Empirically Outperform Differential Privacy against Membership Inference", "Cache Me If You Can: Accuracy-Aware Inference Engine for Differentially Private Data Exploration", "Majority in the Three-Way Comparison Model"], "Faculty_Members": null, "Research_Areas": ["Databases and Data Management", "Security and Privacy"]}, "research_experience": [{"research_area": "Databases and Data Management", "projects": "BlowfishDB", "skills": ["Algorithm design", "Interactive system development", "Interface design", "Testing and evaluation"], "description": "Developed an interactive system that allows data curators to specify personalized privacy guarantees and data analysts to query under such privacy guarantees. Contributed to the formalization of a new privacy notion, Dynamic Blowfish, and implemented key algorithms for query- answering interface. This project culminated in a demo paper presented at VLDB 2021, showcasing the system's usability and performance guarantees.", "collaboration": "Worked closely with graduate students and Professor Xi He, participating in team discussions and leading the writing and demonstration efforts for the research paper.", "recommendation": "Professor Xi He highlighted Jerry's key role in the completion of the demo work, noting his ability to produce an end-to-end prototype, and contribute significantly to the formalization and proofs for the new privacy notion."}, {"research_area": "Databases and Data Management", "projects": "Query Response System (Ongoing)", "skills": ["Algorithm implementation", "Prototype development", "Problem solving", "User testing"], "description": "Working on a system that reuses cached responses to answer incoming queries differentially privately. Addressed a flaw regarding matrix compatibility and implemented an algorithm to transform matrices, contributing to the establishment of a viable system architecture. Extensively designed use-cases and conducted tests to assess system functionality.", "collaboration": "Joined the project midway and integrated into ongoing team efforts, adapting to existing structures while leading discussions on optimizing query responses and active testing against various use cases.", "recommendation": "Professor Xi He praised Jerry's ability to quickly identify bottlenecks and develop useful test cases, demonstrating his teamwork and communication capabilities."}, {"research_area": "Security and Privacy", "projects": "Membership Inference Attacks", "skills": ["Machine learning techniques", "Implementation and experimentation", "Data analysis", "Documentation"], "description": "Evaluated differential private stochastic gradient descent as a defense against membership inference attacks on deep neural networks. Jerry was responsible for implementing various machine learning strategies, executing detailed experiments, and documenting results with precision to ensure reliability and replicability for publication.", "collaboration": "Collaborated with postdoc Simon Oya and other team members, suggesting new research directions and maintaining motivation throughout project challenges, reflecting perseverance and team dynamics.", "recommendation": "Florian Kerschbaum, Jerry's professor, noted his top-tier status among students, emphasizing his inquisitiveness in suggesting innovative research directions and his commitment to achieving reliable results despite setbacks."}]}]