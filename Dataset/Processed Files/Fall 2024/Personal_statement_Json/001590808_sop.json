{
  "document_name": "Inamdar, Amogh (001590808).pdf",
  "total_pages": 3,
  "pages": [
    {
      "page_number": 1,
      "content": "Inamdar, Amogh; DOB: 06/24/1998; ID: 001590808\nAmogh Inamdar\nData analysis underpins intelligent decision making, and data representation begets analysis.\nRepresentation learning shows promising results in distilling information from big data, but its top\nperforming algorithms are hard to understand and deploy as resilient systems. Studying these challenges\nwas central to my experience as a Master’s student at Columbia University, where I discovered the joys of\ndiving deep into machine learning through academic research. Through a career in research via the Ph.D.\nprogram at Columbia, I aim to engineer algorithms that represent data better, leverage them in end-to-end\napplications, and work towards provable AI explainability.\nExplainability has long been a key aspect of my research - in my very first graduate research project\n(supervised by Dr. Ansaf Salleb-Aouissi), I worked with doctors from New York-Presbytarian to create a\ndataset of spinal deformity patients from HIPAA-protected demographic and medical information.\nSupervised by Dr. Ansaf Salleb-Aouissi, I used a battery of random forest algorithms with gradient\nboosting to classify post-operative Proximal Junctional Kyphosis (PJK), a complication that often\nnecessitates re-surgery in patients. By aggregating decision trees and validating calculated risk factors for\nPJK, I presented potentially actionable insights to medical experts at a regular cadence. Through this, I\nlearned that explainability in AI is non-negotiable in critical fields like medicine, and to design systems that\nbalance explainability with data privacy. Working in medicine was also extremely rewarding.\nHabituated to task-specific deep learning, I was fascinated by self-supervised learning when I studied the\nSimCLR algorithm in a class taught by Dr. Richard Zemel. To explore further, I began working with Dr.\nZemel on contrastive attribute learning. I adapted the SimCLR algorithm to learn vectors composable\nfrom subspaces via multi-head instance discrimination, to constrain variation in image data to perceivable\n‘attributes’ like shape and color. Experimenting on the dSprites and CelebA datasets showed that weakly\nsupervised models outperformed self-supervised counterparts on attribute-level tasks, corroborating\ntheoretical findings from Locatello et. al. 2019. Gratifyingly, visualizing data in representation space with\nt-SNE also qualitatively linked disentanglement and performance. Based on these results, I shifted focus\nto studying whether large text-image models such as CLIP and Flamingo can leverage language\nassociation for zero-shot learning through experiments on attributes datasets like MIT-states. This project\n1\n10/07/2024 09:54 Personal Statement 1/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 2,
      "content": "Inamdar, Amogh; DOB: 06/24/1998; ID: 001590808\nAmogh Inamdar\nsparked my interest in disentangled representations, few-shot learning, and domain adaptation, and I see\nthese as potential focal points of my Ph.D. research. I continue to contribute to it as a working\nprofessional and enjoy it greatly.\nI also have a strong record of engineering praxis. Guided by Dr. Nakul Verma and Dr. Salleb-Aouissi, I\nbuilt logiclearner.ctl.columbia.edu, a propositional logic practice app, for the Center for Teaching and\nLearning at Columbia. I developed a system to parse and generate a search frontier for Boolean\nexpressions, optimized heuristics with a genetic algorithm, and adapted A* search to solve logic proofs.\nThrough my research, LogicLearner provides hints on-the-fly from wherever a student may be stuck,\nwhich cannot be achieved by precomputing solutions. Recognizing a unique opportunity for\nself-supervision, I developed a large question bank by backtracking from solution states and used a\nSiamese GRU to embed expressions in vector space, preserving transition similarity according to logic\nrules. Used as a heuristic, this network solved many human-generated questions in under a second.\nLogiclearner has been used in Dr. Salleb-Aouissi’s discrete math class at Columbia, and has motivated\nme to further study representation learning for non-perceptual tasks. Currently, as a software engineer at\nSalesforce, I build and manage highly optimized systems that control millions of dollars of cloud\ninfrastructure for the Genie customer data platform.\nHaving worked closely with Dr. Richard Zemel at Columbia, I am keen on continuing my exploration of\nrepresentation learning and generalizability as a Ph.D. student in his group. Working full-time as a\nsoftware engineer on a data-driven stack has only reinforced my belief in the need for agile machine\nlearning models. With Dr. Zemel, I hope to explore the frontiers of such models and build robust,\nexplainable models that generalize from small amounts of data. As a returning student, I would be able to\nmake meaningful contributions from day one. Dr. Carl Vondrick’s excellent computer vision course served\nas my introduction to representation learning, and I was fortunate to take Dr. Zemel’s course alongside his\naccomplished students. Being especially interested in computer vision, I hope to work on research under\nhis guidance. I am also excited by the breadth of interdisciplinary research at Columbia. While I wasn’t\nable to work with Dr. Liam Paninski during my MS due to visa work limits, I was privileged to have\n2\n10/07/2024 09:54 Personal Statement 2/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 3,
      "content": "Inamdar, Amogh; DOB: 06/24/1998; ID: 001590808\nAmogh Inamdar\ninteracted with him on research in pose estimation. My experience with medical and cognitive science\nmake me well-suited to tackle the fascinating research in computational neuroscience that Dr. Paninski’s\ngroup focuses on.\nOverall, Columbia University presents an ideal environment for my growth as a researcher, with an\nincredible peer group and faculty with diverse research interests. Through my Master’s degree, I have\ndemonstrated excellence in intense graduate coursework and both core and interdisciplinary research at\na high level. My data engineering profession has also made me a strong coder and system designer. My\ntime at Columbia was immensely rewarding but all too brief - as a Ph.D. student, I would mature as an\nacademic and gain a breadth of perspective. After my degree, I plan on continuing research in machine\nlearning and its applications as a research scientist. In the long term, I hope to have a career in\nacademia, combining my love for research and pedagogy as a university professor.\n3\n10/07/2024 09:54 Personal Statement 3/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    }
  ]
}