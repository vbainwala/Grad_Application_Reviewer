{
  "document_name": "Tolentino Veliz, Jose (961615821).pdf",
  "total_pages": 3,
  "pages": [
    {
      "page_number": 1,
      "content": "Tolentino Veliz, Jose; DOB: 06/30/1991; ID: 961615821\nJose Antonio Tolentino Veliz\nStatement of Purpose\nMy affinity for programming began back in 2013 when I took my first programming courses. I was\namazed exactly the moment when I could write a small C++ snippet that could trick a game to make\nusers always win. Apparently, it was nothing transcendental; however, I had to study the physical laws\nthat govern the virtual game environment to elaborate an algorithm that could solve the puzzle.\nUndoubtedly, that must have been a milestone that defined my growing interest in computers.\nDriven by this enthusiasm, in 2015 I joined Smart Machines Lab in charge of Professor Jose Oliden at\nCTIC-UNI, a tech club specializing in autonomous robotics and microsatellites. In September 2016,\nmy team participated in the ARLISS tournament, launching a two-meter rocket size with a small Rover\ninside. The objective was to deploy the rover mid-air and then navigate it autonomously to a specific\nGPS coordinate in the Rock desert of Reno, Nevada. Afterward, I was awarded a scholarship to\nreceive training in the CanSat program at the University of Hokkaido, where the focus was to develop\nand launch a nanosatellite up to 500 feet to perform telemetry.\nIn subsequent years, my research focus shifted to Control Systems and Artificial Intelligence. In 2018,\nI presented a research thesis to control the water level on a multi-tank system utilizing a coupled PID\ncontroller with a Genetic Algorithm, where I successfully improved the performance of traditional\ncontrol techniques. The effectiveness and reliability of my control system apparatus prompted me to\nfile a patent for this implementation.\nIn 2020, I launched a Startup called QbAI. Initially, I began doing research in collaboration with my\nuniversity in the area of autonomous vehicles. The purpose was to lay the groundwork for the\nsoftware implementation of an urban VTOL (Rail), which later turned into two papers published in\n2021 and 2022. Parallel to this project, I was developing front-end and back-end applications for local\nclients. In 2022, I decided to launch a startup based in New Mexico called Scryper, because I was\ngetting more international clients and wanted to broaden my market niche. My focus by then was\nclearer, I wanted to target the development of Software as a Service that can leverage LLM/ML and\nAI.\n10/07/2024 09:54 Personal Statement 1/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 2,
      "content": "Tolentino Veliz, Jose; DOB: 06/30/1991; ID: 961615821\nJose Antonio Tolentino Veliz\nIn consideration of the foregoing, I’m aiming to study for a Ph.D. in Computer Science because I\nwould like to propose solutions to critical problems that society deals with on a daily basis. For\ninstance, in the area of transport, I started a project to study the implementation of an urban\nautonomous electric aircraft (RAIL) that is able to navigate to a desired destination, just by booking a\nride via a mobile application. This idea was presented to Y Combinator this present year 2023, where\nI submitted the autonomous navigation software, the booking mobile application, and the aircraft’s\nstructure design. Although there are many areas in this project that need research and development,\nlike computer vision, fluid dynamics simulation, FPGA circuit board design, etc. I perceive that it’s\ncompletely achievable because, in the past, I followed a similar engineering process when I built the\ncontrol system apparatus of my patent that is now used by hundreds of students at my university.\nMoreover, in a robotics application like the autonomous aircraft, it’s necessary to lean on sensor\nfusion to collect as much data as possible from cameras and sensors, and then process it according\nto the aircraft’s motion using powerful FPGAs and computer vision-oriented software.\nHence, it’s crucial to define and study flight paths to prevent collisions because VTOLs will usually fly\nbelow commercial flights. In addition to those challenges, it is important to also consider the impact of\nweather conditions on the safe navigation of autonomous cars. Professor Baishakhi Ray's research,\ntitled \"DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars,\" sheds light\non this aspect. Their study revealed that traditional testing approaches often overlook critical faults in\nDNN models, leading to potential accidents in autonomous cars. Recognizing the significance of this\nissue, Professor Ray and her team introduced DeepTest as a solution to enhance the efficiency and\ncode coverage of testing in autonomous cars, achieving an impressive 99.6% coverage, and\ncontributing to making autonomous cars safer and more reliable on the road.\nComputer vision captivates my attention and I am eager to explore its diverse application areas, such\nas generating code, images, or realistic video and photo renders. For instance, Professor Carl\nVondrick and his team, in their paper titled \"ViperGPT: Visual Inference via Python Execution for\nReasoning,\" introduced an innovative model that improves visual inference accuracy by 87%\nprecision. In their work, they demonstrated that their model leverages efficient Python execution that\nexhibits a remarkable 4.5x speed improvement compared to traditional processes. Surprisingly, these\n10/07/2024 09:54 Personal Statement 2/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 3,
      "content": "Tolentino Veliz, Jose; DOB: 06/30/1991; ID: 961615821\nJose Antonio Tolentino Veliz\nexceptional outcomes are attained with just an image as input, highlighting the model's versatility and\npotential impact across various applications. I have come across an application idea called\nUnrealCode, which is the line of the aforementioned research. UnrealCode aims to be a platform that\ncreates code based on drawing blocks. Since I have been in the development of Front-end and Back-\nend, I have experienced the repetitive task of writing code for modules that are already defined. For\ninstance, the code to create a user in Django is already implemented, so why not generate these\nmodels through front-end design? The procedure would be that a user draws blocks, for example, a\nlogin form and the LLM generates the front-end and back-end ready-to-use code according to the\nparameters of the form’s graphical design, such as font color, sizes, position of images, buttons, etc.\nTo conclude, after my studies, I plan to put into practice my knowledge in the technology industry or\nby launching software services through a startup. I’m utterly sure my professional experience and\nacademic research will fit in a Ph.D. in Computer Science like the one offered at Columbia University,\nwhere I have found that my projects are closely related to their recent publications.\n10/07/2024 09:54 Personal Statement 3/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    }
  ]
}