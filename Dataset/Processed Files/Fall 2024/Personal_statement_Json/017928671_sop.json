{
  "document_name": "He, Jiaxing (017928671).pdf",
  "total_pages": 3,
  "pages": [
    {
      "page_number": 1,
      "content": "He, Jiaxing; DOB: 02/18/1998; ID: 017928671\nPersonal statement\nWith strong interest and motivation, I am determined to apply to your PhD program in\nComputing and Data Sciences at your prestigious university and would like to use this brief\npersonal statementtohighlightmyacademicbackgroundandresearchinterests.Beforethat,I\nshould say how much I respect Columbia University, both for its well-knownreputationand\nfor her great contributions to scientific research. My academic goals are properly metbythe\ncompetent program design and great faculty team there. I have solid grounds for believing\nthat this Ph.D. program will help me grow professionally so that I can achieve my career\ngoals of becoming an engineer, a senior researcher inatechnologycompany,oranacademia\nprofessor in the future, which is exactlyinlinewiththeprogram’sdesigngoalandconvinces\nmethatImadetherightchoice.\nSince 2021, I have been enrolled inthemaster’sprogramofDataScienceatTuftsUniversity\nwith an educational background in Statistics from GuangdongUniversityofForeignStudies.\nTherefore, it iseasytoseefrommypastacademicperformancethatIhaveestablishedasolid\nfoundation of knowledge in the two areas mentionedabove,particularlyinregardtosubjects\nlike Mathematical Statistics, Probability Theory, Advanced Mathematics, Applied Statistics,\nAlgorithms, Statistics Pattern Recognition, Data Mining, Deep learning, Machine Learning\nandsoforth.\nIn my past study, I have placed a special emphasis on the courses of Machine Learning\nPrinciples and its framework programming like Python & Java programming, in addition to\nmy proficiency in Pytorch, and Scikit-learn machine learning framework. My PhD stage’s\nprimary focuswillalsobeonmachinelearning.IintendtolearnmoreaboutFederallearning,\nDeep graph learning, Natural language processing, Generative model diffusion, Application\nof graph data, and Graph machine learning, and learn somemathematicscoursesinMachine\nLearning, such as Stochastic process, Information theory,Bayesianmachinelearning,etc.,to\nimprove my mathematical derivation and my capacity to turn objective problems into\nmathematical problems. Besides, I want to conduct more projectprogramming,completethe\nproject from scratch, increase my proficiency at translating mathematical issues into\ncomputer language, work on generative models/algorithms, and improve theinadequaciesof\ncurrentgraphgenerativemodels.\nWhat affected me mostwasthecourseStatisticPatternRecognitiontaughtbyDr.IsaacLage.\nThisclasstaughtmemanyprobabilisticmodels,suchastheHiddenMarkovModel,Gaussian\nmixture model, and k-means algorithm. Also, I learned how to perform inference through\nMCMC and variational inference. I think theclasspavedasolidfoundationformystatistical\nlearningbackground,whichhelpedmealotinmyfuturemachinelearningresearch.\nIn the deep learning course taught by Prof. Liping Liu, I found myself veryintotheclasson\ngenerative modeling. In this class, I comprehensively learned about various neural networks\nsuch as RNN, transformer, and CNN. What excited me the most was the course project I\n10/07/2024 09:54 Personal Statement 1/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 2,
      "content": "He, Jiaxing; DOB: 02/18/1998; ID: 017928671\nworked on, in which I did style transformation by using cycleGAN. In thisproject,Itriedto\ninnovate the loss function and discriminator architecture. Specifically, I reweighted\nadversarial loss, cycle consistent loss, and identity loss to see how the image style would\nchange accordingly. Besides, I simplified the discriminator to make the optimization of the\ngenerator easier. Though my ideas did not improve over the original model, I became more\ninterestedingenerativemodelsanddeeplearning.\nTo better have hands-on experience, I have worked on two projects related to graph\ngeneration, one was to benchmark the generative performance over one-shot and sequential\ngraph generative models, and the second was to develop graph generative models that meet\ndifferentialprivacy.\nThe goal of the first project was to provide a fair comparison of two kinds of generative\nmodels in terms of the likelihood metrics. Since one-shot generative models are usually\npermutation-invariant and sequential generative model depends on the generating orders,\nthese two models are not directly comparable due to the marginalization over the\npermutation. In this project, my first duty was to derive the log-likelihood for the one-shot\ngenerative models, by taking the permutation into consideration. This leads me to get\nfamiliar with the mechanism of flow-based generative models and how to model discrete\ndata. While thelog-likelihoodcalculationiswell-establishedinsequentialgenerativemodels,\nmy second duty is to run extensive experiments tocomparethesetwokindsofmethods,thus\nbridging the two models over this more universal metric. I am fortunate to be advised by\nProf. Liu Li-ping on this project. I learned a lot about the basic techniques of Variational\nInference, data dequantization, and a broad class of Graph Neural Networks. Furthermore, I\nlearn how to code with graph data structure, which is more complicated than imageandtext\ndataasitsirregulardatarepresentation.\nThe second project was accepted by ICML2023. Its main goal is to generate graphs that\npreserve the graph statistics without leaking the users’ privacy in the training graphs.\nHowever, current deep graph generative models cannot generate large networks with\nsatisfying graph statistics. The first goal of this project is to developascalableandpowerful\ngraph generative model, which leads us to first turn our attention to the diffusion model.\nDuring the development of the new diffusion graph model, I am responsible for\nimplementing a batching training procedure, which speeds up the training and reduces the\ngradient variance. Besides, I derived the posterior of the non-uniform diffusion forward\nkernel. When working on the derivation, I had a deep understanding of how the diffusion\nmodels are derived, which [made me gain more understanding generative model. Besides, I\nread plenty of papers on differential privacy with graph data and papers about how to use\ndifferential privacyandcreatedata.Afterdevelopingsuchamodel,Iwillfocusongenerating\nlargenetworkswithprivacyguarantees.\nObjectively speaking, I choose machine learning as the major topic of my Ph.D. research\nprimarily due to my advantages in statistics, mathematics, and computer knowledge and\nskills. Considering statistics, as an illustration, Machine Learning uses techniques like\n10/07/2024 09:54 Personal Statement 2/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 3,
      "content": "He, Jiaxing; DOB: 02/18/1998; ID: 017928671\nMarkov Monte Carlo Sampling, Bayesian inference, conditional probability in diffusion\nmodels, and ELBO derivation in variational auto-encoders, etc., which makes statistics\napplications extremely valuable and further piques my interest. Recently, machine learning\nhas developed a number of extremely potent capabilities, such asthechatGPT3thatwasjust\nreleased, which has made me realize the enormous potential and development space in this\nfield of study, and greatly inspired me to invest in further research and exploration of\nmachinelearning.\nBecoming anexpertinthedomainsofgraphmachinelearninggenerativemodels,andnatural\nlanguageismyprofessionallife’sambition.\nIn a sense, myresearchsupervisorandFeynmanarethetwopeoplewhohavehadthebiggest\ninfluences on my intense interest and motivation in scientific research. My mentor is a\nserious thinker, whose dedication to research and analytical approach has had a significant\nimpact on me. He always challenges me to speak with mathematics, articulate ideas with\nmathematics, and approach issues with rigorous and abstract mathematical thinking during\nour academic sessions. My knowledge of the issue gradually deepened afterdiscoveringthis\nsophisticated mathematical statement, and I started to pay closer attention to my\nmathematical prowess. TheotherpersonisFeynman,whohadagreaterspiritualinfluenceon\nme, and whose quote I use as my motto. In aninterview,thehostquestionedFeynmanabout\nthe significance of astronomical research. He responded that in truth, it may not have much\nsignificance or significantly improve people’s lives, but learning itself is the best purpose\nsince it allows us to better understand the world and explore the unknown. Yes, seeking\nknowledge is the greatest purpose and joy, thus I believe conducting research calls for this\nkindofmindset.\n10/07/2024 09:54 Personal Statement 3/3",
      "metadata": {
        "width": 612,
        "height": 792
      }
    }
  ]
}