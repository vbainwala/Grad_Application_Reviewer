{
  "document_name": "Lau, Wai Tak (413834948).pdf",
  "total_pages": 1,
  "pages": [
    {
      "page_number": 1,
      "content": "Lau, Wai Tak; DOB: 04/13/1999; ID: 413834948\nMichael Lau\nNew York, NY • wl2822@columbia.edu • 6303627274 • LinkedIn • Github\nSUMMARY\nResearcher skilled in machine learning, software development and data analysis with Python. Ready to contribute clean,\nefficient code to build systems. Strong collaborator, communicator, and initiative-driven to enhance research efforts.\nEDUCATION\nColumbia University New York, NY\nM.S. Electrical Engineering, Concentration: Machine Learning, GPA: 3.67/4.0 Feb 2023\nCourses: Probabilistic Models and Machine Learning, Reinforcement Learning, Causal Inference 1 & 2, Natural Language\nProcessing, Sparse Low-Dimensional Models, Statistical Learning, Deep Learning\nUniversity of Illinois at Urbana-Champaign Champaign, IL\nB.S. (Hons) Computer Engineering, GPA: 3.58/4.0 May 2021\nHonors: Dean’s List (x2)\nCourses: Machine Learning, Algorithms, Deep Learning in Hardware, Image and Video Processing, Artificial Intelligence,\nDigital Signal Processing, Data Structure, Computer Security, Audio Computing Lab, Abstract Linear Algebra\nSKILLS\n• Python, C++, C, PyTorch, TensorFlow, R, SQL, GCP, AWS, JavaScript, HTML, MATLAB, CSS, Assembly, Git, CAD,\nDocker, scikit-learn, SciPy, Pandas\nWORK EXPERIENCE\nColumbia University March 2023 - Present\nResearch Assistant - AI4VS Lab New York, NY\n• Developing and proposing self-supervised learning for ophthalmology where labels are scarce, utilizing eye tracking\ndata and OCT reports for robust predictions and representation learning.\n• Leverage success in NLP to model eye tracking data based on BERT and Sentence-BERT to learn embeddings\n• Creating and conducting experiments, processing data to train deep learning models; implemented SimCLR and\nDINO from scratch with PyTorch and PyTorch Lightning.\n• Training, fine-tuning and validating Computer Vision models, leveraging domain knowledge from medical experts to\nguide model development, achieving 95% test-set accuracy in addition to improved interpretability\nLatentAI Jun 2022 - Aug 2022\nMachine Learning Engineer Intern Princeton, NJ\n• Developed pruning methods on image recognition models using PyTorch, archived guaranteed 40% increase in\ninference speed on YOLOv5 Tiny.\n• Designed experiments to test hypothesis on different pruning strategies to increase inference speed on edge devices.\n• Programmed software tools in Python for standardized scalable deep learning experiments and; integrated pruning\ninto LatentAI’s end-to-end pipeline, benchmarking pruned models on target edge devices for the first time to assess\ninference time and accuracy.\nLiveSensus Jan 2020 - May 2021\nCo-Founder Champaign, IL\n• Built a machine learning model and open-sourced dataset consisting of 30 hours of audio, labeled with MOS scores\nfor quality estimation during Vo-IP.\n• Designed and developed simulators to re-create quality degradation in both videos and audios for dataset and survey\nlaunched on AWS and LiveSensus website.\n• Collaborated with four other founders, Professor Sanjay Patel and a leading live streaming company, five founders\nselected from 40 students under Alchemy Foundry at UIUC’s Coordinated Science Laboratory.\nPROJECTS\nVision Transformer for Glaucoma Classification using OCT Scans Dec 2022\n• Proposed using Vision Transformer (ViT) for Glaucoma classification. Then use Latent Dirichlet Allocation (LDA) to\ninterpret ViT’s classification decisions on the neural network’s attention weights across layers.\n• Achieved 95% test-set accuracy with ViT; used attention rollout to combine per OCT scan heatmap of important\nregions; LDA discover representations used by ViT for classification.\nNeural Causal Model for Image-to-Image Translation May 2022\n• Designed and built a Neural Causal Model from scratch, consisting of deconvolution neural network and U-Nets\ntrained as WGAN, for more robust conditional Image-to-Image translation.\n• Trained Neural Causal Model with Cityscape Dataset, where the G-constrained architecture takes labeled image and\na set of covariates that guides the translation of the image.\n10/07/2024 09:57 Resume 1/1",
      "metadata": {
        "width": 611,
        "height": 791
      }
    }
  ]
}