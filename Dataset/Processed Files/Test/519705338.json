{
  "document_name": "Zhang, Andy (519705338).pdf",
  "total_pages": 4,
  "pages": [
    {
      "page_number": 1,
      "content": "Andy Zhang\nAlbany, CA, 94706 | (510) 717-3420 | az99@g.ucla.edu | https://www.linkedin.com/in/azhang25/ | https://github.com/andyz2021\nEducation\nUniversity of California, Los Angeles (UCLA) B.S, Computer Science\nGPA: 4.0/4.0 Expected June 2025\nExperience\n• ByteDance Inc. Software Engineer Intern (06/2024-09/2024)\no Develop highly scalable recommendation models to improve advertisement recommendation accuracy\no A/B test new iterations of TensorFlow models with added features and a transformer architecture\no Increased TikTok’s advertiser revenue in the US by 8% and Tiktok’s revenue by 4%, due to model modifications\n• Lawrence Berkeley National Laboratory Student Assistant(Link) (06/2023-09/2023)\no Developed a web tool to display power usage time series information for Perlmutter, a supercomputer at LBNL.\no Wrote Python scripts to process data queried from VictoriaMetrics time series database, and output to JS and PHP frontend\no Display time vs power usage graph and enable users to see which applications were taking up the most power and why.\n• Computational Diagnostics Lab Student Researcher (04/2023-present)\no Helping develop a transformer model to predict hospital readmission based on adherence and fitness data.\no Predict whether patients would be readmitted within the next seven days based on steps, heart rate, and more.\no Integrate model with a mobile health app with the goal of providing patients with better care from home.\n• Predictive Science Inc. Computing/Solar Physics Intern (link) (04/2022-09/2022)\no Implemented a redesign of the PSI website used to model data from NASA on the Solar Corona and Heliosphere.\no Used React to build a new interface for displaying plots and inputting data into form fields.\no Migrated backend from legacy PHP system to Django, and deployed new website intended to be used by researchers.\nProjects\n• Grounded: (link)\no Developed a mobile app in 10 weeks designed to promote mindfulness and get away from social media.\no Utilized React Native to help create a navigation bar, take photos, and add friends through QR codes.\no Implemented backend through Firebase to store photos and login information.\no Tested app through Expo CLI, deployed app intended to be available on iOS and Android.\n• BruinYelp: (link)\no Worked with team members to create a web application to allow students to voice their opinions on UCLA food.\no Built dynamic display of food reviews and images, navigation menu, and search/sort functionalities through React.\no Created Firebase backend that allowed for Google Authentication and storing user reviews.\n• PsiPy: (link)\no Created new features and fixed bugs in PsiPy, a tool for visualizing MHD models from Predictive Science Inc.\no Added the ability for users to specify file type and font size when reading in hdf files through Python.\no Developed a pipeline to call Fortran functions in Python using Numpy’s f2py tool.\nPublications:\n• Zhang A, Bhalachandra S, Deng S, Zhao Z, NPAT - A Power Analysis Tool at NERSC, August 2023; Lawrence Berkeley National\nLaboratory. https://doi.org/10.1145/3624062.3624149\nExtracurriculars\n• Upsilon Pi Epsilon: CS Honor Society. Tutored students, attended professional events, and practiced mock interviews.\n• Bruin Sports Analytics: Wrote sports articles backed up with self-created graphs and data. (link)\nRelevant Coursework\nData Structures and Algorithms, Software Construction, Operating Systems, Artificial Intelligence, Statistics for Engineering, Programming\nLanguages, Computer Architecture, Computer Vision, Databases, Machine Learning, Web Applications, Computer Networks.\nTechnical Skills\n• Coding: C++, C, Python, Java, Django, JavaScript, React, HTML, TensorFlow, Keras, SQL, Haskell, Pytorch, Fortran, PHP, MongoDB.\n• Technologies/Environments: Github, Gitlab, Linux, Visual Studio Code, Docker, Kubernetes, Jupyter Notebook, PostgreSQL.",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 2,
      "content": "AndyZhang PhDApplication,ComputerScience,ColumbiaUniversity\n“Howcanacomputertellthedifferencebetweencatsanddogs?”Irememberaskingmyselfthisquestion\ncountlesstimeswhenmymomfirsttoldmeaboutAlexNetinmiddleschool.Iwasfascinatedbytheidea\nthatacomputercoulddifferentiatebetweenobjectsintherealworld—ataskthatIhadthoughtofas\ndistinctlyhumangiventhatitrequiredtheuseofoursenses.Thisignitedmyinterestincomputervision,\nandmydesiretodiscoverwhatnoveltaskscomputerscoulddo.Ifurtherexploredthatideathrough\nindependentresearchunderDr.BoussardatStanford,andasaparticipantinprogramssuchasthe\nSummerSTEMInstitute,theBioinformaticsAIResearchLabatUCLA,andLawrenceBerkeleyNational\nLaboratory.Doingseriousresearchhasaffirmedmypassionfortechnicalandchallengingprojects.My\nobjectiveistopursueaPhDprograminComputerSciencewithafocusonartificialintelligence,\nspecificallycomputervisionanditsapplicationsatColumbiaUniversity.\nMyresearchjourneyindeeplearningstartedunderDr.BoussardatStanford’sBiomedicalInformatics\nResearchLab,whereIinvestigatedacomputervisionmethodinparsingpatient-reportedmedical\nsurveys.Withover20,000InternationalProstateSymptomScore(IPSS)multiplechoicesurveys,itwas\nimportanttodevelopanefficientwayofdetectingpatientresponses.Wedevelopedamachinelearning\npipelinethatcoulddetectpatientmarks.TheHoughLineTransformwasusedtopreprocessthesurveys,\nandanalyzeonlytheportionwiththemarks.Then,theimageswerepassedtoGoogle’sCNNMobileNet\ntodetectwhichcellwasmarked.Iwasresponsiblefordeveloping,debugging,andoptimizingthe\nalgorithm.Thisprocessofdevelopingastate-of-the-arttool,experimenting,andwritingaboutourfindings\nwasanincredibleintroductiontomachinelearningandtheresearchworld.Althoughourworkdidn’tend\nupbeingpublished,Ilearnedtoreflectonfeedbackandgrewasaresearcher.Thisintroductionto\nresearchpiquedmyinterestinthecapabilitiesoflarge-scaledeeplearning.\nAttheSummerSTEMInstitute,Iworkedalongsideagraduatestudenttoperformanindependent\nresearchproject.There,IdevelopedatransferlearningapproachtoclassifyingCT-scansof\nnon-small-celllungcancer.Lungcancerisoftenhardtodetectandclassify,andevenifdetected,can\nalreadybeintheadvancedstages.Inanefforttohelpdetectsignsoflungcancerearlier,Iutilized\nGoogle’sInceptionV3CNN,pre-trainedontheImageNetdataset.Thetrainingandtestdatawasobtained",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 3,
      "content": "AndyZhang PhDApplication,ComputerScience,ColumbiaUniversity\nfromtheNSCLC-Radiomicsdataset,withCT-scansfromover400patients.Themodelwasfine-tunedon\nlungcancerscans,andclassifiedbetweenadenocarcinoma,squamouscellcarcinoma,andlargecell\ncarcinoma.Itobtainedanaccuracyof78%,comparabletostate-of-the-artlungcancerimage\nclassificationmethodsatthetime.AsthefirstprojectwhereIwasresponsibleforeverystepfromstartto\nfinish,Igrewasanindependentandautonomousresearcher.Thisprocessalsotaughtmetheprocessof\nwritinganengagingpaper,somethingIendedupdoinginmynextresearchexperience.\nMymostmemorableresearchexperienceatLawrenceBerkeleyNationalLaboratoryledtomepublishing\nmyfirstpaper.InaninvestigationofpowerusageandefficiencyundertheNationalEnergyScientific\nResearchComputingCenter,IdevelopedtheNERSCPowerAnalysisTool(NPAT),atooltoprovidequick\nandaccuratepoweranalysisoftheirnewestsupercomputer,Perlmutter.Perlmuttercollectsavastamount\nofdataeverysecond,but,beingatime-consuminganddifficultprocess,gettingthedesireddatacanbe\nchallenging.WedevelopedNPATtohelpimprovepowerefficiencyinfuturesystemsandbetter\nunderstandthepowersignatureofcurrentsupercomputingworkloads.Itprovidesaquickandaccessible\nwaytoviewthepowerusagedataofNERSCsystems,jobs,andapplications.Iwasresponsiblefor\ndevelopmentanddeploymentofNPAT,aswellasthewritingandeditingofthepaper.Ipublishedthis\nfirst-authorpaper[1]inSC23,andpresenteditattheHUSTworkshopatSC23.Publishingapaperwasan\nincrediblethrill,andIwasdelightedtopresentandexplainourcontributionstoothers.Iespeciallyvalued\nthisprojectduetotheimmediateandtangibleimpactithadonNERSCusers.\nInordertodeepenmyskills,Ipursuedopportunitiesthroughlabandclasswork.AsamemberofUCLA’s\nBiomedicalArtificialIntelligenceResearchLab,I’mdevelopingatransformer-basedapproachtopredicta\npatient’ssymptomseveritybasedontheiractivityandadherencedata.Thisdataincludessteps,heart\nrate,timeasleep,caloriesburned,aswellasadherencedatalikewhethertheysyncedtheirFitbitortook\ntheirmedication.Theeventualgoalistointegratethispredictionintoamobilehealthappthatcanprovide\npatientswithcarefromhome.Additionally,aspartofaComputerVisionforDeepLearningclass,I\ncreatedaresearchpresentationondepthestimationandthestate-of-the-artmethodology.Itincluded\nCNN-basedapproaches,aswellasDepthAnything,whichutilizesbothlabeledandunlabeleddata,as",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 4,
      "content": "AndyZhang PhDApplication,ComputerScience,ColumbiaUniversity\nwellasanencoder-decoderarchitecture.Igainedskillsinworkingcloselyalongsidegraduatestudents,\nandcollaboratingonlargerscaleprojectswherecommunicationiscrucial.\nMyexperienceshavecollectivelyshapedmyresearchinterestsandmotivatedmetopursuegraduate\nstudies.Today,computervisionisincrediblyimportantinavarietyoffields.Ihopetodevelopnew\nmethodstoenhanceathleticperformance,improvethesafetyandreliabilityofself-drivingcars,and\ndetectandclassifydiseaseslikecancer.WatchingtheNBAchangebecauseofanalyticsasIgrewup,\nandhearingaboutthemillionswhopassawayduetocaraccidentsandcancereachyear,I’mmotivated\ntodevelopapplicableandpracticalsolutionsthatcanfurtherthefieldofcomputervision.Howcan\nathletestrainmoreeffectively?Howcanself-drivingcarslearntonavigatedifficultsituationsinrealtime?\nHowcanwedetectlungcancerearlyandaccurately?Withadeepunderstandingoftheproblemspace,\nandwithskillsgainedthroughsolvingproblemsinthisspace,Ihopetosolvetheseproblemsbyapplying\nAIincomputervisiontohelppeoplelivetheirbestlives.\nColumbia’sAIprogram’srecentworkshowsitsuniquestrengthsinmytopicsofinterest.Specifically,I\nwouldbeexcitedtoworkwithDr.PeterBelhumeurandDr.Shih-FuChang.Dr.Belhumeur’sworkon\ncomputervisionandmachinelearning,especiallyDogsnapandBirdsnap,arerelatedtomyexplorationof\ncomputervision,especiallyintherecognitionfield.Extendingmyworkunderhissupervisionwould\ndeepenmyunderstandingofthepracticalandeverydayapplicationsofcomputervision.Myresearch\ninterestsalsogreatlyoverlapwithDr.Chang’swork,suchashisresearchonR-CNNsandFew-Shot\nObjectDetection.Havingexploredtheseconceptsinclass,Iwouldbeexcitedtobringmyskillsand\nexperienceincomputervisionandneuralnetworkstomyworkwithDr.Chang.\nThecombinationofmypreviousresearchexperienceandinterestshasthoroughlypreparedmeforthe\nacademicrigorofaPhD.IseeanimmediatefitformyskillsandinterestsatColumbiaUniversity.\n[1]ZhangA,BhalachandraS,DengS,ZhaoZ,NPAT-APowerAnalysisToolatNERSC,August2023;\nLawrenceBerkeleyNationalLaboratory.https://doi.org/10.1145/3624062.3624149",
      "metadata": {
        "width": 612,
        "height": 792
      }
    }
  ]
}