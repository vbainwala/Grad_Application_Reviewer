{
  "document_name": "Villanueva, Callyn (760709946).pdf",
  "total_pages": 5,
  "pages": [
    {
      "page_number": 1,
      "content": "Callyn I. Villanueva\n191-07 37th avenue, APT4H Flushing, NY 11358\n+1 718-517-0917\nGithub\nSUMMARY Ibuilddevices—sometimesincludingrobots—toexplorehumanperceptionandinter-\naction with autonomous systems. My goal is to deepen our understanding of human\nbehavior in dynamic, technology-driven environments. Currently, I am a high school\nComputer Science educator and co-leader of a robotics program.\nINTERESTS Signal processing, human-(computer/robotic) interaction, affective computing.\nACADEMIC M.S. Computer Science (Distinction) 2020\nBACKGROUND New York Institute of Technology, New York, NY\n• Research in Affective Computing under direction of Dr. Houwei Cao. Thesis\ntitle: Analysis of Eye Fixations During Emotion Recognition in Talking Faces\n• Graduate Mentor Dr. Sandra Kopecky\nB.A Psychology, Cognitive Science 2015\nHofstra University, Hempstead,NY\n• Focus Areas: Psychology, Linguistics, Neuroscience (Project: Impaired Cogni-\ntive Process in Attention Deficits)\n• Undergrad Research Mentor Dr. Jin Shin\nRESEARCH Intern Fall 2021\nQuantitative Neuroimaging Lab, Weill Cornell Medicine\n• Acquired foundational knowledge in utilizing neuroimaging software tools, in-\ncluding Freesurfer and FSL, for cortical surface reconstruction from MRI to\ninvestigate negative BOLD response (NBR)\nGraduate Research Assistant Jan 2020 - May 2021\nHuman-Centric Data Analytics Lab, New York Institute of Technology\n• Collected real-time eye fixation data using the Tobii Pro Software eye tracking\nsystem, ensuring precise and accurate measurements.\n• Implementedanewapproachtoanalyzingemotionalperception&gazefixation\nby grouping selected audio & visual stimuli from the (CREMA-D) dataset\nTEACHING HS Technology Instructor & Developer Present\nGrace Church School, New York, NY\n• Together with Dr. Akbar Herndon, we continuously improve curriculum ma-\nterials for technology courses (Harvard CS50, Digital Tools & Citizenship),\nensuring alignment with academic objectives.\n• FIRSTRoboticsCoach-Assistinghighschoolteammemberswithwritingcode\nto control robot in FTC Onbot JAVA in preparation for Qualifiers\nSubject Expert Teacher July 2022 - May 2023\nBASIS Independent Brooklyn, Brooklyn, NY\n1",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 2,
      "content": "• Middle & high school (grades 7-12) computer science teacher specializing in\ncomputer programming instruction, particularly in introductory college-level\ncourses. Courses Taught: AP CS A, AP CS Principles, Intro to Python Pro-\ngramming & Scratch\n• MentoredHSStudentRiver(Rohan)W.onseveralMLprojectssuchas: Build-\ning Neural-Network from scratch(Using Numpy package) & sentiment-driven\nstock price prediction using news API.\nGraduate Teaching Assistant Sep 2019 - Dec 2020\nNew York Institute of Technology, New York, NY\n• AssistedteachingundergraduatelevelcomputersciencecourseswithDr. Wenjia\nLi, averaging over 60+ students. Courses Taught: Computer Programming II\n(CSCI 185 - OOP with Java), Computer Programming Concepts (CSCI 318)\nNOTABLE BUBBLE-BOI In Progress*\nPROJECTS\n• Currently developing a small, autonomous robot capable of blowing bubbles\nusing the Tiva Series Launchpad microcontroller. Designed and implemented\nmotor control, bubble blowing mechanisms, and tweaking sensor-based naviga-\ntion to create an interactive experience.\nChroma-Chords (TinyML) Project Link\n• BytrainingtheArduinoNano33BLESensewiththeGTZANdatasetofaudio\nsamples, the system accurately classifies music into various genres in real-time\nand provides user experience through dynamic LED color display. Model de-\nployed as a C++ library\nSPECIAL Awards\nACHIEVEMENTS • ComputerScienceGraduateAchievmentAward CollegeofEngineering&Com-\nputing Science, New York Institute of Technology, 2020\n• Undergraduate Research Presentation Award, SUNY Farmingdale, 2015\nSKILLSET • Research: User Evaluations (Statistical analysis, Methodologies & Design, In-\nterviews).\n• Languages & Frameworks: Python, C/C++, TensorFlow, PyTorch, Keras,\nOpenCV, R Robot Operating System (ROS), Linux (Bash Scripting)\n• Electronics and Hardware Programming Experience in hardware-oriented soft-\nwaredevelopment: Arduino,RaspberryPi,ARMCortex-M4F-basedmicrocon-\ntroller.\n2",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 3,
      "content": "Statement of Purpose\nof Callyn Villanueva (CS PhD for Fall 2025)\n)\nMy objective is to pursue a Ph.D. in Computer Science, focusing on developing systems that range\nfrom computer-aided technology to human-robot interaction. I am particularly interested in creating\ninnovative solutions for exceptional individuals facing challenges in communication, motivation,\nand emotion regulation, while also enabling robots and computers to respond intelligently to natural\nhuman feedback.\nMy motivation to pursue a Ph.D. is largely based on my accumulated research experience in the\nmultidisciplinary fields of Computer Science, Engineering, and Psychology. This includes working\nunder Dr. Houwei Cao in the Human-Centric Data Analytics Lab and collaborating with Dr. Jin Shin\nduring my Senior Research Project. I have also worked alongside with notable professors in their\nprojects (Dr. Sandra Kopecky - Lecturer at NYIT & Pace University along with Dr. Razlighi in the\nQuantitative Neuroimaging Lab). These ventures into serious research over the past few years have\naffirmed my passion for technical projects.\nDuring my time at the Human-Centric Data Analytics Lab, I addressed questions surrounding\nhow humans perceive emotion based on facial expressions and how this perception influences their\noverall understanding of emotional communication. In a pilot study titled Analysis of Eye Fixations\nDuring Emotion Recognition in Talking Faces, I developed a novel approach to analyzing\nemotional expressions by categorizing audio and video data from the CREMA-D dataset into three\ndistinct groups: Congruent, Incongruent, and Synthetic. This methodology allowed for a more\nnuanced examination of how eye fixations interact with and respond to different emotional cues in\nmultimodal stimuli. This work addresses a significant gap in research on emotion recognition, as\ntraditional studies often focused on facial or vocal cues in isolation, overlooking the complex\ninterplay between these cues in real-world communication. By working on this innovative\napproach, I aimed to enhance our understanding of how individuals process and interpret emotional\ninformation when facial and vocal cues either align or conflict.\nAdditionally, we propose to develop a novel emotion perception classifier that can automatically\nclassify an observer’s emotional perception based on their gaze patterns and fixation sequences\nwhile identifying basic emotions in expressive talking faces. The proposed models achieved an\noverall classification accuracy of 84.1 (percent) in recognizing three categories of emotions:\nnegative, positive, and neutral. These findings suggest that the fixation time on the selected AOIs",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 4,
      "content": "Statement of Purpose\nof Callyn Villanueva (CS PhD for Fall 2025)\n)\nholds significant promise for the automatic classification of perceived emotions\nI have also worked on a project with Dr. Kopecky along with a research colleague, Christian\nOliveto, aimed at developing a deep learning-based system for analyzing eye tracking data to assist\nin the early diagnosis of autism spectrum disorder (ASD). This innovative system was trained on a\ncomprehensive dataset of eye tracking recordings from both individuals with ASD and neurotypical\nindividuals, enabling it to learn patterns associated with ASD-related gaze behaviors. Preliminary\nresults have shown that the Sequential FNN model achieved high accuracy for both the training and\nvalidation datasets. In addition to classification accuracy, ANOVA tests conducted on various eye\ntracking metrics revealed significant differences between individuals with ASD, neurotypical\nindividuals, and those labeled as Unidentified.\nIn 2019, I had the opportunity to work as a graduate teaching assistant under the guidance of Dr.\nWenjia Li. During this time, I had the privilege of instructing several undergraduate courses,\nincluding CSCI 125 (Computer Programming I), CSCI 185 (Computer Programming II), and\nCSCI318 (Programming Language Concepts), each centered around Java programming. In the\nSpring of 2022, I extended my teaching journey to encompass middle and high school computer\nscience. This opportunity enabled me to introduce young minds to the world of programming,\nguiding them through foundational courses and mentoring high school students. In essence, my role\nas an educator extends beyond the dissemination of information. Alongside with research, I am\ncommitted to nurturing a new generation of computer scientists who possess not only technical\nexpertise but also the ability to innovate and adapt in an ever-evolving field.\nIn conclusion, the findings and approaches I have explored throughout my research journey have\nsolidified my commitment to finding innovative solutions using computer- aided technology and\nrobotics. My goal is to develop systems that not only enhance understanding and diagnosis of\nconditions like autism spectrum disorder but also empower individuals to navigate the world more\neffectively. If I pursue my Ph.D. studies at Columbia University’s School of Engineering & Applied\nScience, I aim to leverage advancements in deep learning and human-computer interaction to create\nadaptive technologies that promote emotional and social engagement. I am excited about the\npotential to transform lives through research that bridges the gap between technology and human\nexperience.\nAlthough I do not yet have publications, my experience in conducting high-level research has",
      "metadata": {
        "width": 612,
        "height": 792
      }
    },
    {
      "page_number": 5,
      "content": "Statement of Purpose\nof Callyn Villanueva (CS PhD for Fall 2025)\n)\nequipped me with a strong foundation in the methodologies and ethical considerations essential\nfor impactful inquiry. I’m currently drawn to several research initiatives at Columbia, including\nthe Computer-Enabled Abilities Laboratory (CEAL) under the direction of Brian Smith, Zhou\nYu’s Lab, which focuses on human-machine communication, and the Robotics and Embodied\nArtificial Intelligence Lab led by Shuran Song. I am committed to contributing to a vibrant academic\ncommunity at Columbia that prioritizes innovation and inclusivity in technology.",
      "metadata": {
        "width": 612,
        "height": 792
      }
    }
  ]
}