{
    "ID": "001590808",
    "SOP": "Amogh Inamdar Data analysis underpins intelligent decision making, and data representation begets analysis. Representation learning shows promising results in distilling information from big data, but its top performing algorithms are hard to understand and deploy as resilient systems. Studying these challenges was central to my experience as a Master\u2019s student at Columbia University, where I discovered the joys of diving deep into machine learning through academic research. Through a career in research via the Ph.D. program at Columbia, I aim to engineer algorithms that represent data better, leverage them in end-to-end applications, and work towards provable AI explainability. Explainability has long been a key aspect of my research - in my very first graduate research project (supervised by Dr. Ansaf Salleb-Aouissi), I worked with doctors from New York-Presbytarian to create a dataset of spinal deformity patients from HIPAA-protected demographic and medical information. Supervised by Dr. Ansaf Salleb-Aouissi, I used a battery of random forest algorithms with gradient boosting to classify post-operative Proximal Junctional Kyphosis (PJK), a complication that often necessitates re-surgery in patients. By aggregating decision trees and validating calculated risk factors for PJK, I presented potentially actionable insights to medical experts at a regular cadence. Through this, I learned that explainability in AI is non-negotiable in critical fields like medicine, and to design systems that balance explainability with data privacy. Working in medicine was also extremely rewarding. Habituated to task-specific deep learning, I was fascinated by self-supervised learning when I studied the SimCLR algorithm in a class taught by Dr. Richard Zemel. To explore further, I began working with Dr. Zemel on contrastive attribute learning. I adapted the SimCLR algorithm to learn vectors composable from subspaces via multi-head instance discrimination, to constrain variation in image data to perceivable \u2018attributes\u2019 like shape and color. Experimenting on the dSprites and CelebA datasets showed that weakly supervised models outperformed self-supervised counterparts on attribute-level tasks, corroborating theoretical findings from Locatello et. al. 2019. Gratifyingly, visualizing data in representation space with t-SNE also qualitatively linked disentanglement and performance. Based on these results, I shifted focus to studying whether large text-image models such as CLIP and Flamingo can leverage language association for zero-shot learning through experiments on attributes datasets like MIT-states. This project 1 Amogh Inamdar sparked my interest in disentangled representations, few-shot learning, and domain adaptation, and I see these as potential focal points of my Ph.D. research. I continue to contribute to it as a working professional and enjoy it greatly. I also have a strong record of engineering praxis. Guided by Dr. Nakul Verma and Dr. Salleb-Aouissi, I built logiclearner.ctl.columbia.edu, a propositional logic practice app, for the Center for Teaching and Learning at Columbia. I developed a system to parse and generate a search frontier for Boolean expressions, optimized heuristics with a genetic algorithm, and adapted A* search to solve logic proofs. Through my research, LogicLearner provides hints on-the-fly from wherever a student may be stuck, which cannot be achieved by precomputing solutions. Recognizing a unique opportunity for self-supervision, I developed a large question bank by backtracking from solution states and used a Siamese GRU to embed expressions in vector space, preserving transition similarity according to logic rules. Used as a heuristic, this network solved many human-generated questions in under a second. Logiclearner has been used in Dr. Salleb-Aouissi\u2019s discrete math class at Columbia, and has motivated me to further study representation learning for non-perceptual tasks. Currently, as a software engineer at Salesforce, I build and manage highly optimized systems that control millions of dollars of cloud infrastructure for the Genie customer data platform. Having worked closely with Dr. Richard Zemel at Columbia, I am keen on continuing my exploration of representation learning and generalizability as a Ph.D. student in his group. Working full-time as a software engineer on a data-driven stack has only reinforced my belief in the need for agile machine learning models. With Dr. Zemel, I hope to explore the frontiers of such models and build robust, explainable models that generalize from small amounts of data. As a returning student, I would be able to make meaningful contributions from day one. Dr. Carl Vondrick\u2019s excellent computer vision course served as my introduction to representation learning, and I was fortunate to take Dr. Zemel\u2019s course alongside his accomplished students. Being especially interested in computer vision, I hope to work on research under his guidance. I am also excited by the breadth of interdisciplinary research at Columbia. While I wasn\u2019t able to work with Dr. Liam Paninski during my MS due to visa work limits, I was privileged to have 2 Amogh Inamdar interacted with him on research in pose estimation. My experience with medical and cognitive science make me well-suited to tackle the fascinating research in computational neuroscience that Dr. Paninski\u2019s group focuses on. Overall, Columbia University presents an ideal environment for my growth as a researcher, with an incredible peer group and faculty with diverse research interests. Through my Master\u2019s degree, I have demonstrated excellence in intense graduate coursework and both core and interdisciplinary research at a high level. My data engineering profession has also made me a strong coder and system designer. My time at Columbia was immensely rewarding but all too brief - as a Ph.D. student, I would mature as an academic and gain a breadth of perspective. After my degree, I plan on continuing research in machine learning and its applications as a research scientist. In the long term, I hope to have a career in academia, combining my love for research and pedagogy as a university professor. 3",
    "Resume": "Amogh Shreedhar Inamdar linkedin.com/in/amoghinamdar amogh.inamdar@columbia.edu github.com/AmoghSInamdar EDUCATION Columbia University New York, NY M.S. in Computer Science - Machine Learning track; GPA: 4.0/4.0 May 2022 Ramaiah Institute of Technology Bengaluru, IND B.E. in Computer Science and Engineering ; GPA: 9.76/10 Aug 2020 ACADEMIC RESEARCH Columbia University New York, NY Graduate Researcher; Advisor: Dr. Richard Zemel Feb 2022 - Present Contrastive Learning of Disentangled Representations \u25cf Extended the SimCLR algorithm to novel supervised and unsupervised contrastive attribute learning paradigms. \u25cf Visualized the effects of data supervision on learned image representation spaces with PCA and t-SNE. \u25cf Developing methods to evaluate the performance of large pretrained models on attribute learning tasks. Graduate Researcher and Developer; Advisor: Dr. Nakul Verma Oct 2021 - Jun 2022 LogicLearner: a tool for learning propositional logic ( logiclearner.ctl.columbia.edu) \u25cf Developed a grammar for predicate logic with the Lark parser-generator in Python. \u25cf Designed a novel frontier-generation algorithm by implementing logic rules as parsed-expression transforms. \u25cf Implemented A* search and optimized heuristics with a genetic algorithm to solve propositional logic proofs. \u25cf Embedded logic statements as vectors using a Siamese GRU network optimizing for a dot-product A* heuristic; achieved strong problem-solving performance. Graduate Researcher; Advisor: Dr. Ansaf Salleb-Aouissi Jun 2021 - Sep 2021 Categorization of post-operative Proximal Junctional Kyphosis (PJK) in spine deformity patients \u25cf Collaborated with medical staff bi-weekly to design and standardize a proprietary dataset of spinal deformity patients to study the post-operative complications of spinal surgery. \u25cf Leveraged ensemble learning to analyze data, characterize post-operative PJK, and take steps towards predicting revision surgery in a highly imbalanced dataset while emphasizing algorithmic explainability. Ramaiah Institute of Technology Bengaluru, IND Undergraduate Researcher; Advisor: Dr. Seema S Jan 2020 - Jul 2020 Efficient Handwriting Generation of English Text with Conditional GANs \u25cf Combined image stitching heuristics with lightweight conditional GANs to generate handwritten English text from typed input efficiently (>40 chars/second) in Tensorflow. \u25cf Built a web application to generate handwriting from input text using HTML5/CSS and Flask in Python. Undergraduate Researcher; Advisor: Dr. Sangeetha J Jan 2019 - Dec 2019 Time-Dynamic NEAT: a Validation-based Heuristic for Neuroevolution on Large Datasets \u25cf Formulated TIDY NEAT, a heuristic for exponentially scaling data input to NEAT evolutionary algorithm. \u25cf Demonstrated a 3.3x faster convergence to equal accuracy as vanilla NEAT on a cardiovascular disease classification task and supported time complexity results with qualitative analysis. Amogh Inamdar - CV 1 The Indian Institute of Science Bengaluru, IND Academies\u2019 Summer Research Fellow at IISc; Advisor: Dr. Balaji Jayaprakash Jun 2018 \u2013 Aug 2018 Monte Carlo Simulation of Problem-Solving Behavior in Rats \u25cf Modeled learning via memory consolidation in rats by simulating brain grid cells and a Morris Water Maze experiment with Monte Carlo methods and reinforcement learning in C++. \u25cf Developed a GUI to run trials, visualize simulated rat paths, and generate and store results and heatmaps, using the and Java Swing framework. TEACHING EXPERIENCE Department of Computer Science, Columbia University New York, NY Course Assistant - COMS 4771 Machine Learning Feb 2022 - Jun 2022 \u25cf Instructor: Dr. Nakul Verma ; As described below. Course Assistant - COMS 4771 Machine Learning Jun 2021 \u2013 Sep 2021 \u25cf Instructor: Dr. Nakul Verma ; Enrollment: 70+ undergraduate and graduate Columbia students. \u25cf Held office hours to solve student doubts, graded assignments, and assisted with course logistics. Course Assistant - Machine Learning, Columbia-edX AI Micromasters (MOOC) Feb 2021 \u2013 May 2021 \u25cf Instructor: Dr. John Paisley ; Enrollment: 322 online learners taking graduate-level coursework. \u25cf Answered doubts on course material, exams, and logistics on a student forum for the ML course. Ramaiah Institute of Technology Bengaluru, IND Special Lecture \u2013 Data Mining Dec 2019 \u25cf Instructor: Prof. Sowmya BJ; Enrollment: 60+ undergraduate juniors. \u25cf Delivered a lecture on data mining practices and dataset pre-processing for deep learning. PROFESSIONAL EXPERIENCE Salesforce San Francisco, CA AMTS Software Engineer \u2013 Salesforce Genie Jun 2022 - Present \u25cf Building Salesforce Genie, a hyperscale data platform providing a unified customer data interface for real-time CRM. \u25cf Developing tools to provision and manage millions of dollars of infrastructure on AWS EMR and EKS platforms. \u25cf Engineering resilient infrastructure enabling data warehousing and real-time streaming analytics at massive scale. Software Engineer Intern \u2013 ML Services team, Einstein Platform Jun 2021 \u2013 Sep 2021 \u25cf Designed and developed a Python SDK for real-time scoring of customer service requests with machine learning. \u25cf Enabled experimentation and debugging in a production-like environment across cloud tenants and ML models. \u25cf Reduced effort for model experimentation from several steps taking hours to a single step taking a few minutes. AI Model Share Initiative, Columbia University New York, NY Developer (Part-time) Mar 2021 \u2013 Jun 2021 \u25cf Created an API to enable the Model Share library to deploy customized pre-trained ML models as AWS Lambda endpoints reachable by AWS API Gateway. \u25cf Prototyped AWS CloudFormation integration to enable modular deployments of AI Model Share infrastructure. Amogh Inamdar - CV 2 Cadence Design Systems Bengaluru, IND Software Engineer Intern \u2013 R&D team, Pegasus Verification System Jul 2020 \u2013 Sep 2020 \u25cf Devised a C++ engine to improve Pegasus Design Rule Check performance and integrated it into Pegasus flow. \u25cf Enhanced automated test generation for microchip density and fill characteristics in Python \u25cf Created complex test cases with KLayout editor and evaluated and debugged Pegasus in Linux. Samsung Research Institute Bangalore Bengaluru, IND Research Intern - PRISM Program for Undergraduate Research in AI Apr 2019 \u2013 Nov 2019 \u25cf Led a student research team in On-Device AI to create an SQLite to Apache Lucene Query Parser with Antlr4 in Java. \u25cf Presented results to an open floor of 300+ Samsung engineers at a showcase for the top 20% of all intern projects. \u25cf Received a Certificate of Excellence for exceeding KPIs for processing time and memory utilization by 5-10x. HONORS and AWARDS Ranger Certification - Salesforce Trailhead learning platform Sep 2022 Best Student Award - Computer Science, Ramaiah Institute of Technology Aug 2020 Certificate of Excellence - Samsung PRISM Undergraduate Research Program Nov 2019 Summer Research Fellowship in 2018, Indian Academies of Science Jun 2018 TECHNICAL SKILLS Languages Python, Java, C/C++, R, SQL, JavaScript, HTML5/CSS, UNIX shell scripting Tools AWS, K8s, ML tools (PyTorch etc.), Parser-generators, MongoDB, Apache Lucene, Flask Amogh Inamdar - CV 3"
}