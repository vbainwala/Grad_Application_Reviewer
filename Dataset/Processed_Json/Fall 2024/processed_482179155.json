{
    "ID": "482179155",
    "SOP": "Huangyuan Su Fall 2024 Personal Statement My past research interest lies in the intersection of reinforcement learning (RL) with robotics, computer vision, language models, and gametheory, etc. What excitesme themost isto develop agentsor algorithmsthat arerobustand generalizable. Applied ReinforcementLearning andRobot Learning As a MS in Machine Learning studentatCarnegieMellonUniversity, Ihave hadtheprivilege to work under the supervision of Prof. Jeff Schneider and Prof. Ruslan Salakhutdinov. My first project at CMU found that the anchor embeddings used by recent trajectory prediction approaches can parameterize distinct discrete modes representing high-level driving behaviors. We propose to perform fully reactive closed-loop planning over these discrete latent modes, allowing us to tractably model the causal interactions between agents at each step. We validate our approach on a suite of dynamic merging scenarios, finding that our approach avoids the frozen robot problemwhich ispervasive inconventional planners.Our approachoutperformsthe previous art inCARLA on challengingdense trafficscenarioswhenevaluated atrealistic speeds. In the next project [4], we use diffusion models to perform language-guided closed-loop planning for autonomous driving. Counter to conventional wisdom, we show that excessive conditioning information can hinder downstream planning performance due to poor generalization and lack ofdiversity. Additionally,weshowthat gradient-basedoptimization(e.g. classifierguidance)canactually perform worsethan sampling-basedoptimization(e.g. CEM/ES) for guided diffusion sampling. To this end, we introduce a novel sampling-based guidance method DiffusionES which handles arbitrary non-differentiable black-box objectives without retraining. We use LLMs to map language instructionsto programswhich adaptivelycontrolthe behavior of our planner through reward shaping. With language supervision, our approach can synthesize highly complex behaviors (e.g. aggressive lane weaving) not present in the training data. Finally, we show that our approach can be used to solve the hardest nuPlan scenarios through languagefeedbackfrom ahumanexpert. After submitting these two projects to ICRA 24 and CVPR 24, we started work on using video games for studying human-AI or multi-agent collaborative decision making in disaster management. With Prof. Salakhutdinov, we have been working on solving robotic control problems under domain randomization across tasks and robot morphologies (hand, dog, arm) by distilling classical optimization algorithms(MJPC) into visuomotorpolicies. Improving Reinforcement LearningAlgorithms using TheoreticalTools In my first research project [1] during my bachelor at Nanyang Technological University, we tackled the failure of standard Policy iteration (PI) relies on Bellman\u2019s Principle of Optimality under time-inconsistent (TIC) objectives, such as non-exponentially discounted reward functions. Specifically, we consider an infinite-horizon TIC RL setting and formally present an alternative type of optimality drawn from game theory: subgame perfect equilibrium, that attempts to resolve the aforementioned questions. Drawing on these observations, we propose backward Q-learning, a new algorithm in the approximate PI family that targets SPE policy under non-exponentiallydiscountedreward functions. Huangyuan Su Fall 2024 Then [2], I noticedthat the learnedrepresentationof a\ud835\udc44-networkand itstarget should,intheory, satisfy a favorable distinguishable representation property. Specifically, there exists an upper bound on the representation similarity of the value functions of two adjacent time steps in a typical DRL setting. However, in experiments, the DRL agents may violate this property and obtain asuboptimalpolicy.Therefore,weproposeasimple yeteffectiveregularizercalled Policy Evaluation with Easy Regularization on Representation, to maintain the distinguishable representationproperty.These twoworksarepublishedin TMLRandCVPR 23,respectively. Futureplan In my previous research endeavors, a significant portion of my time was dedicated to refining model architectures and hyperparameters. This challenge is exacerbated in the realm of RL, where the optimization of distinct parameter sets for different scenarios within the same task is common practice. This intricate process poses a significant obstacle when attempting to deploy our agents in real-world settings. Issues such as data shifts and long-tail scenarios often lead to system failures. Given the current momentum in industry towards integrating AI workers to complement or substitute human roles, it becomes imperative for these AI entities to possess specific qualities, including robustness, safety, and consistency. Additionally, an essential attribute is their capacity for reasoning, enabling them to produce decisions that are not only refined but also explainable to humans. The ability to incorporate feedback for continuous improvementiscrucial, as theconsequences of inadequateperformance canbe severe. While certain studies [5, 6] suggest that agents based onLLMsoutperformRLagentsor exhibit zero-shot generalization, it is evident that their generalization capabilities remain constrained. Consequently, I strongly advocate for the development of better architectures, frameworks, or training schemes. For the first year of my PhD, I plan to explore various avenues, including leveraging generative (pre-)training for robust 3D recognition, distilling knowledge from pretrained LLMs to mitigate the intensive sample requirements for training autonomous agents, and addressingthepaucity oftheoretical analysisindeep learningmethods. Looking ahead, my career goal is to work as a professor, contributing to research that yields trustworthy AIagentsor systems,while mentoringandguiding motivatedstudents. Why ColumbiaUniversityandComputerSciencePh.D.? Based on my experiences, I've come to recognize that effective problem-solving and the discovery of new, compellingchallenges require guidancefromthe mosttalented, insightful, and experienced researchers. Among them, I am particularly drawn to the distinguished faculty at Columbia University, including Junfeng Yang, Carl Vondrick, Zhou Yu, Richard Zemel, and Tony Dear. Their groundbreaking contributions in vision, NLP, and robotics, occasionally influenced by RL, strongly resonate with my researchinterests.A thorough examinationof their research, coupled with insights gained from perusing their lab environments, has strengthened my desire to collaborate with them. In enrolling in thisCS PhDprogram, myforemost goalis to undergo systematic and comprehensive research training, honing my skills in problem-solving, enriching my expertise in my specific area while fostering a broad understanding of the field. The program's resources for students planning faculty careers is particularly attractive, as it alignsseamlessly withmy long-term aspirationsof contributingmeaningfullyto academia. Huangyuan Su Fall 2024 References: [1] Lesmana,NixieS., Huangyuan Su,andChi SengPun. \"Reinventing PolicyIterationunder TimeInconsistency.\"Transactions onMachineLearningResearch(2022). [2] Qiang He,Huangyuan Su,XinwenHou, YuLiu. \u201cFrustratinglyEasy Regularizationon RepresentationCan Boost DeepReinforcementLearning\u201d. 2023IEEEComputer Society ConferenceonComputer VisionandPattern Recognition. [3] BrianYang, Huangyuan Su,Nikolaos Gkanatsios,Tsung-Wei Ke,AyushJain,Jeff Schneider,KaterinaFragkiadaki. \u201cControllable diffusion-basedplanning for language-guided driving\u201d. 2024In submission. [4] Adam Villaflor,Brian Yang,Huangyuan Su,Katerina Fragkiadaki,JohnM. Dolan,Jeff Schneider.\u201cTractableJoint Predictionand Planningover Discrete BehaviorModes for Urban Driving\u201d.2024In submission. [5] Wang,Guanzhi,etal.\"Voyager:An open-endedembodiedagent withlargelanguage models.\"arXivpreprint arXiv:2305.16291 (2023). [6] Wu, Yue,etal.\"SPRING:GPT-4 Out-performs RLAlgorithms byStudyingPapersand Reasoning.\"arXivpreprintarXiv:2305.15486(2023).",
    "Resume": "Su, Huangyuan; DOB: 07/11/2000; ID: 482179155 huangyus@andrew.cmu.edu, suhither@gmail.com \u22c4 (+1)4126264994 https://www.linkedin.com/in/huangyuan-su/ EDUCATION Carnegie Mellon University, United States Aug 2022 - Nov 2023(Expected) \u2022 Master of Science in Machine Learning. GPA: 3.9/4.0. \u2022 Research Assistant (Auton Lab). Teaching Assistant (10708: Probabilistic Graphical Models). Nanyang Technological University, Singapore Aug 2018 - Jun 2022 \u2022 Bachelor of Science in Mathematical Sciences; Computing and Data Analysis Minor. Highest Distinction. 4.82/5.00. Dean\u2019s List (Top 5% GPA, Academic Years 2020-2021, 2018-2019). \u2022 Full scholarship recipient (NTU Science and Engineering Scholarship). University of California, Los Angeles, United States Summer School. Jun 2019 - Aug 2019 WORK EXPERIENCE Research Assistant (Large Language Models, Self-Driving), Carnegie Mellon University Aug 2022 - Dec 2023 Supervised by Prof Jeff Schneider Work on a transformer/diffusion-based formulation to handle multimodality in imitation learning for driving while following natural language instructions. Our aim is to harness the power of language feedback as an additional source of supervision to enhance the feedback loop of conventional autonomy stacks. Research Assistant (Robotic Manipulation), Carnegie Mellon University Aug 2023 - Dec 2023 SupervisedbyProfRuslanSalakhutdinov. Solveroboticcontrolproblemsacrosstasksunderdomainrandomizationandrobot morphologies (hand, dog, arm) by distilling classical optimization algorithms (MJPC) into visuomotor policies. Research Intern (Computer Vision), Peloton Interactive, United States Jun 2023 - Aug 2023 Designedanone-shotskeleton-basedactionrecognitionmethodthat(1)achievesSOTAperformanceonNTURGB+D120and NW-UCLA; (2) gets a high accuracy on proprietary dataset. Significantly advanced the capability of Guide (a core product). Machine Learning Engineer Intern (AI/ML Team), Apple May - Aug 2021 Derived insights using Spark as to how well the personalized Today feed in App Store is performing for our users across 150+ storefronts and identify opportunities for improvement. Used the insights to optimize apps recommended to users and built dashboards to monitor the performance of different recommendation algorithms. PUBLICATIONS Diffusion-ES: Generative Evolutionary Search with Diffusion Models for Trajectory Optimization Brian Yang, Huangyuan Su, Nikolaos Gkanatsios, Tsung-Wei Ke, Jeff Schneider, Katerina Fragkiadaki. In submission. We propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function in the form of natural language, using LLMs. Model-Based Planning with Stochastic Trajectory Prediction Models for Urban Driving Adam Villaflor, Huangyuan Su, Brian Yang, John M. Dolan, Jeff Schneider. In submission. Weconsidertrajectorypredictionapproachesthatleveragelearnedanchorembeddingstopredictmultipletrajectories,finding thattheycanparameterizediscretelocallyconsistentmodesrepresentinghigh-leveldrivingbehaviors. Weproposeclosed-loop planning over these discrete latent modes to tractably model the causal interactions between agents at each step. Frustratingly Easy Regularization on Representation Can Boost Deep Reinforcement Learning Qiang He, Huangyuan Su, Xinwen Hou, Yu Liu. 2023 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Reinventing Policy Iteration under Time Inconsistency. Transactions on Machine Learning Research 2022. Lesmana, Nixie S., Huangyuan Su, and Chi Seng Pun. AWARDS & COMPETITIONS Bronze Medal, International Mathematics Competition (IMC20), UK July 2020 Achieved Bronze Medal in this global individual Olympics competition involving top universities including MIT, etc. Honorable Mention, International Student Cluster Competition (ISC2020), Germany Feb 2020 - June 2020 Achieved Honorable Mention (4th place). Building HPC and AI applications using CUDA/OpenMP/Machine Learning. SKILLS Languages: Python (with PyTorch, Tensorflow, JAX, Caffe2), C/C++, shell scripting, GO, SQL, LaTex, R, etc. Others: CUDA programming, OpenMP/OpenCL, Linux, Android Application Development, embedded systems, etc."
}