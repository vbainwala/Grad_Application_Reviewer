{
    "ID": "085541001",
    "SOP": "My parents asked me a question when I had just received my college offer: \"What is your life's goal? Is it money or position?\" I couldn't provide an immediate answer, but this question continued to linger in my mind. During my junior year, I had the opportunity to intern at Beijing Automotive Group Co., Ltd. (BAIC), where I assisted in powertrain calibration. The job was enjoyable, but I yearned for more freedom in product development. Fortunately, during my graduate studies at Johns Hopkins, I was privileged to work in SMARTs lab. Although the resources and project scope at the university were incomparable to the vehicle design work at BAIC, I found immense satisfaction in the freedom to develop my projects. It was during this time that I came to understand my life's true goal. It wasn't about money or fame. As an engineer, my life's purpose is to create something beneficial for the world. This realization set me on a path to pursue a Ph.D. degree. I aspire to secure a research position in an institute or company, where I can explore new ideas and create innovations. A Ph.D. is the foundational step on this journey, leading me toward the fulfillment of my life's goal.\" Based on my previous experience and my interesting. I want to join the Columbia University CS PHD Program and focus on MR Application/Robotics visual servoing or Visualization and Computer Graphics study. My Ph.D. career will build upon the knowledge and experience I gained during my master's program. I graduated from the JHU MSE Robotics program in May 2023, where I acquired a substantial foundation in robotics-related subjects and conducted research at LCSR. I gained expertise in various areas, including Linux, ROS (Robot Operating System), Unity, AR/VR development, gaze tracking, computer vision, and machine learning. I also have practical experience with the Da Vinci Research Kit (dVRK). My involvement at JHU centered around two major research projects: the development of a robotic surgery first assistant training tool and the creation of a VR Virtual Dizziness Clinic. The robotic surgery first assistant training tool originated as a course project. I enrolled in the Computer Integrated Surgery II class, where I undertook a semester-long project under the guidance of Professor Peter Kazanzides. The project stemmed from the recognition that the role of the first assistant is pivotal in the success of robot-assisted surgeries. There was a lack of available simulators for first assistants to co-train with the primary surgeon who operates the robotic system. I initiated the project by focusing on instrument localization since knowing the precise location of instruments is essential for first assistants to interact accurately within the virtual environment. After evaluating various methods, considering factors such as accessibility, latency, accuracy, and minimizing modifications to the handheld instruments, I decided to employ a stereo camera and traditional computer vision techniques to address this challenge. Once I successfully obtained accurate instrument positions, I designed a pipeline to transmit this information to Unity using a UDP socket, allowing for the correct rendering of instruments within the Unity environment. The course project reached its conclusion due to time constraints, but I was determined to extract more value from the system. Consequently, I continued my work within the lab, aiming to enhance the system. I explored additional features, including endoscope localization via endoscope views, experimented with instrument detection using background subtraction, and attempted to use the disparity map to ascertain the status of the end effectors on the instruments. Although some of these endeavors faced challenges, like issues related to modeling and resource limitations, I successfully transitioned the system from Unity to the Asynchronous Multi-Body Framework (AMBF), an open-source simulation environment developed by research scientist Adnan Munawar at JHU. At this point, the system had evolved to effectively collaborate with the da Vinci Research Kit (dVRK). The initial results of this work were accepted and presented at the International Symposium on Medical Robotics (ISMR). The second project originated from a collaboration with Dr. Kemar Green, a neuro- ophthalmologist. During the COVID-19 pandemic, Dr. Green encountered a significant challenge in telemedicine. For the accurate diagnosis of certain conditions, particularly those related to gaze patterns, neuro-ophthalmologists require precise gaze data. While gaze estimation is possible through video, the data obtained this way may not be as accurate as needed for diagnostic purposes. Unfortunately, sending specialized devices to patients' homes for these measurements was impractical. To address this issue, a solution using off-the-shelf hardware became essential. I conducted a rapid assessment of the task and developed a prototype using the HoloLens 2, which offered a simple user interface and automated data collection, ensuring the quantitative and accurate analysis of gaze patterns. This project is still ongoing, with the initial work aimed at presentation at the IEEE VR conference. Both projects were primarily undertaken by me under the guidance of Professor Peter Kazanzides. Professor Peter provided the overarching vision and valuable insights. I was responsible for designing the pipeline, writing, testing, and debugging the code, as well as creating and modifying the hardware and phantom models. I also received significant assistance from numerous research scientists at the LCSR Lab. This experience allowed me to step out of my comfort zone, beyond classroom learning, and acquire a wealth of new knowledge from practical research. As I reflect on my journey, I find immense satisfaction not only in the outcomes but also in the personal growth I've achieved. My foray into the world of robotics began in the fall of 2021, at a point when I had limited knowledge of Linux, ROS, AR, and computer vision. However, over time, I not only acquired expertise in these areas but also developed the skills to facilitate communication between programs, navigate complex research platforms, and optimize software performance. Equally important was my ability to establish strong connections with my colleagues in the lab. Engaging in research was a profoundly enjoyable experience, one that fueled my intrinsic motivation to create something novel and valuable. This experience markedly contrasted with my prior internship in a large corporation and solidified my decision to pursue a Ph.D. program. In retrospect, it affirmed my capacity for rapid learning, my proficiency in communication, and my unwavering commitment to excel in my Ph.D. journey. I am enthusiastic about specializing in AR/VR, visual servoing, computer graphics, computer vision, and related fields, and I believe that Columbia University is the perfect institution to nurture my growth in these areas. My swift transition from a mechanical background to computer science robotics illustrates my capacity for quick adaptation. Although I didn't take classes on data structures or computer networks, my research experience substantiates my knowledge in the fundamental computer science domains. Furthermore, I haven't overlooked my mechanical knowledge, which includes expertise in control, CAD, and FEA. These skills can significantly enhance my contributions to the field of robotics. I sincerely wish Columbia could allow me to dive further into this area. I am confident that I will be successful in my Ph.D. career and provide a step forward to the community!",
    "Resume": "Haochen Wei 2001 W Cold Spring Ln, Baltimore, MD 21209 | hwei15@jhu.edu | (518) 256 3774 Education: Johns Hopkins University, Baltimore, Maryland Sep 2021 - May 2023 Master of Science and Engineering in Robotics, GPA 3.80/4.00 Rensselaer Polytechnic Institute, Troy, NY Sep 2017 - May 2021 Bachelor of Science in Mechanical Engineering, GPA 3.73/4.00 Research Experience: Sensing, Manipulation, and Real-Time Systems (SMARTS) Lab, Johns Hopkins University Feb 2022 - Now Research Assistant, Advisor: Prof. Peter, Kazanzides Project 1: \u26ab Building an abdominal phantom with instrument tracking for laparoscopic training. \u26ab Dock the abdominal phantom with the Asynchronous Multi-Body Framework (AMBF) and visualize both the handheld instruments and dVRK console side instruments together within the AMBF, facilitating co-training with the MTM side surgeon. \u26ab Conduct a user study to demonstrate the effectiveness of augmented assistance in first assistant training. The results of this study were presented at the 2023 IEEE International Symposium on Medical Robotics (ISMR). Project 2: \u26ab Collaborated with Dr. Chen to utilize gaze tracking devices for real-time point-of-interest visualization during the training process. Project 3: \u26ab Collaborated with Dr. Green to design and develop an augmented reality (AR) based platform for acute vertigo tele-assessment, automating the Head Impulse test, Nystagmus test, and Test of Skew (HINTS). \u26ab This project is currently under review for IEEE Virtual Reality 2024 (IEEE VR 2024). Laboratory of Biomechanical and Image Guided Surgical Systems, Johns Hopkins University Sep 2022 - May 2023 Research Assistant, Advisor: Prof. Alejandro Martin-Gomez \u26ab Designed an augmented reality (AR) interaction method for path planning and distance measurement within 3D Slicer. \u26ab Utilized HoloLens 2 to create a label map, transmitted it to a desktop, and visualized it using the desktop version of 3D Slicer software. Mechanical Aerospace and Nuclear Engineering Department, Rensselaer Polytechnic Institute Jan 2020 - May 2020 Research Assistant, Advisor: Assistant Prof. Mamadou Diagne \u26ab Participated in the project to establish a math model of Sedimentation in the river. \u26ab Designed a CAD model of a gate to control the fluid rate of a small-scale river model. Mechanical Aerospace and Nuclear Engineering Department, Rensselaer Polytechnic Institute Aug 2020 - Dec 2020 Research Assistant, Advisor: Prof. Theo Borca-Tasciuc \u26ab Assist to build a prototype of energy saving building. \u26ab Analyzed the thermal efficiency of existing design by using NX Flow. \u26ab Created a simple tutorial for how to use the NX Flow. Publications: \u26ab Wei, H., Chen, C., & Kazanzides, P. (2023). An abdominal phantom with instrument tracking for laparoscopic training. In 2023 IEEE International Symposium on Medical Robotics (ISMR). \u26ab Wei, H., Bolsey, J., Kuwera, E., Kazanzides, P., & Green,K. (2023). TeleAutoHINTS: A Virtual or Augmented Reality (VR/AR) System for Automated Tele-Neurologic Evaluation of Acute Vertigo. In 2024 IEEE Virtual Reality (IEEE VR).(Under Review) Work Experience: Beijing Automotive Industry Holding Co., Ltd. Beijing, China Sep 2019 - Dec 2019 Intern of Powertrain Calibration \u26ab Assisted in the powertrain calibration. Focused on transmission control unit calibration. \u26ab Analyzed drivability based on IMU data. \u26ab Preliminary research on engine emission estimation model. Skills: \u26ab Programming Language: Python, MATLAB, C++, C# \u26ab OS, Program & Library: Linux, OpenCV, Unity, ROS, MRTK, PyTorch, Git, LaTeX, UGNX, SolidWorks, ZeroMQ, 3DSlicer, Blender \u26ab Language: Mandarin (native speaker), English (fluently) Honors: \u26ab Magna Cum Laude \u26ab Dean\u2019s Honor List on Fall 2018; Spring 2019; Summer 2019; Spring 2020"
}